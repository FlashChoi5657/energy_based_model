{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import os, copy, argparse, configparser\n",
        "import sys, datetime, csv, random\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import PeakSignalNoiseRatio\n",
        "import pytorch_lightning as pl\n",
        "from torchvision.utils import save_image\n",
        "import network_models as models\n",
        "import function_losses as losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ======================================================================\n",
        "# take options \n",
        "# ======================================================================\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--dir_work\", type=str, default='/nas/users/minhyeok/energy_based_model')\n",
        "parser.add_argument(\"--device_cuda\", type=int, default=0)\n",
        "\n",
        "parser.add_argument(\"--model_conv\", type=str, default='conv_double_resnet')\n",
        "parser.add_argument(\"--model_activation\", type=str, default='leakyrelu')\n",
        "parser.add_argument(\"--model_output\", type=str, default='sigmoid')\n",
        "parser.add_argument(\"--model_use_batch_norm\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--model_use_skip\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--model_use_dual_input\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--model_dim_feature\", type=int, default=8)\n",
        "parser.add_argument(\"--model_dim_latent\", type=int, default=100)\n",
        "\n",
        "parser.add_argument(\"--data_name\", type=str, default='MNIST', choices=['MNIST', 'CELEBA', 'CIFAR10', 'sitk'])\n",
        "parser.add_argument(\"--data_use_all\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--data_label_subset\", type=int, default=5)\n",
        "parser.add_argument(\"--data_channel\", type=int, default=1)\n",
        "parser.add_argument(\"--data_height\", type=int, default=32)\n",
        "parser.add_argument(\"--data_width\", type=int, default=32)\n",
        "parser.add_argument(\"--data_noise_sigma\", type=float, default=0.1)\n",
        "\n",
        "parser.add_argument(\"--optim_option\", type=str, default='adam')\n",
        "parser.add_argument(\"--optim_length_epoch\", type=int, default=1000)\n",
        "parser.add_argument(\"--optim_size_batch\", type=int, default=100)\n",
        "parser.add_argument(\"--optim_lr_model\", type=float, default=0.0001)\n",
        "parser.add_argument(\"--optim_lr_energy\", type=float, default=0.0001)\n",
        "parser.add_argument(\"--optim_lr_data\", type=float, default=0.01)\n",
        "parser.add_argument(\"--optim_lr_langevin\", type=float, default=0.0001)\n",
        "parser.add_argument(\"--optim_length_langevin\", type=int, default=50)\n",
        "parser.add_argument(\"--optim_weight_gradient\", type=float, default=0.0001)\n",
        "\n",
        "args = parser.parse_args(args=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# assign options\n",
        "# ======================================================================\n",
        "dir_work                = args.dir_work\n",
        "device_cuda             = args.device_cuda\n",
        "\n",
        "model_conv              = args.model_conv\n",
        "model_activation        = args.model_activation\n",
        "model_output            = args.model_output\n",
        "model_use_batch_norm    = args.model_use_batch_norm\n",
        "model_use_skip          = args.model_use_skip\n",
        "model_use_dual_input    = args.model_use_dual_input\n",
        "model_dim_feature       = args.model_dim_feature\n",
        "model_dim_latent        = args.model_dim_latent\n",
        "\n",
        "data_name               = args.data_name.upper()\n",
        "data_use_all            = args.data_use_all\n",
        "data_label_subset       = args.data_label_subset \n",
        "data_channel            = args.data_channel\n",
        "data_height             = args.data_height\n",
        "data_width              = args.data_width\n",
        "data_noise_sigma        = args.data_noise_sigma\n",
        "\n",
        "optim_option            = args.optim_option\n",
        "optim_length_epoch      = args.optim_length_epoch\n",
        "optim_size_batch        = args.optim_size_batch\n",
        "optim_lr_model          = args.optim_lr_model\n",
        "optim_lr_energy         = args.optim_lr_energy\n",
        "optim_lr_data           = args.optim_lr_data\n",
        "optim_lr_langevin       = args.optim_lr_langevin\n",
        "optim_length_langevin   = args.optim_length_langevin\n",
        "optim_weight_gradient   = args.optim_weight_gradient\n",
        "\n",
        "# ======================================================================\n",
        "# path for the results\n",
        "# ======================================================================\n",
        "now         = datetime.datetime.now()\n",
        "date_stamp  = now.strftime('%Y_%m_%d') \n",
        "time_stamp  = now.strftime('%H_%M_%S') \n",
        "\n",
        "dir_figure  = os.path.join(dir_work, 'figure')\n",
        "dir_option  = os.path.join(dir_work, 'option')\n",
        "dir_result  = os.path.join(dir_work, 'result')\n",
        "dir_model   = os.path.join(dir_work, 'model')\n",
        "\n",
        "path_figure = os.path.join(dir_figure, data_name)\n",
        "path_option = os.path.join(dir_option, data_name)\n",
        "path_result = os.path.join(dir_result, data_name)\n",
        "path_model  = os.path.join(dir_model, data_name)\n",
        "\n",
        "date_figure = os.path.join(path_figure, date_stamp)\n",
        "date_option = os.path.join(path_option, date_stamp)\n",
        "date_result = os.path.join(path_result, date_stamp)\n",
        "date_model  = os.path.join(path_model, date_stamp)\n",
        "\n",
        "file_figure = os.path.join(date_figure, '{}.png'.format(time_stamp))\n",
        "file_option = os.path.join(date_option, '{}.ini'.format(time_stamp))\n",
        "file_result = os.path.join(date_result, '{}.csv'.format(time_stamp))\n",
        "file_model  = os.path.join(date_model, '{}.pth'.format(time_stamp))\n",
        "\n",
        "if not os.path.exists(dir_figure):\n",
        "    os.mkdir(dir_figure)\n",
        "if not os.path.exists(dir_option):\n",
        "    os.mkdir(dir_option)\n",
        "if not os.path.exists(dir_result):\n",
        "    os.mkdir(dir_result)\n",
        "if not os.path.exists(dir_model):\n",
        "    os.mkdir(dir_model)\n",
        "if not os.path.exists(path_figure):\n",
        "    os.mkdir(path_figure)\n",
        "if not os.path.exists(path_option):\n",
        "    os.mkdir(path_option)\n",
        "if not os.path.exists(path_result):\n",
        "    os.mkdir(path_result)\n",
        "if not os.path.exists(path_model):\n",
        "    os.mkdir(path_model)\n",
        "if not os.path.exists(date_figure):\n",
        "    os.mkdir(date_figure)\n",
        "if not os.path.exists(date_option):\n",
        "    os.mkdir(date_option)\n",
        "if not os.path.exists(date_result):\n",
        "    os.mkdir(date_result)\n",
        "if not os.path.exists(date_model):\n",
        "    os.mkdir(date_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 0\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# device\n",
        "# ======================================================================\n",
        "device = torch.device(f'cuda:{device_cuda}' if torch.cuda.is_available() else 'mps')\n",
        "\n",
        "# ======================================================================\n",
        "# random seed\n",
        "# ======================================================================\n",
        "pl.seed_everything(0)\n",
        "\n",
        "# ======================================================================\n",
        "# dataset \n",
        "# ======================================================================\n",
        "dir_data = '/nas/users/minhyeok/dataset'\n",
        "\n",
        "transform = torchvision.transforms.Compose([ \n",
        "    torchvision.transforms.Resize([data_height, data_width]),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # torchvision.transforms.Lambda(lambda t: (t - torch.mean(t)) / torch.std(t)) # mean 0, std 1\n",
        "    # torchvision.transforms.Lambda(lambda t: 2.0 * t - 1) \n",
        "])\n",
        "\n",
        "# the name of the dataset is used as upper case\n",
        "if data_name == 'MNIST':\n",
        "    dataset         = torchvision.datasets.MNIST(dir_data, transform=transform, train=True, download=True)\n",
        "    dataset_test    = torchvision.datasets.MNIST(dir_data, transform=transform, train=False, download=True)\n",
        "\n",
        "elif data_name == 'CIFAR10':\n",
        "    dataset                 = torchvision.datasets.CIFAR10(dir_data, transform=transform, train=True, download=True)\n",
        "    dataset.data            = np.array(dataset.data)\n",
        "    dataset.targets         = np.array(dataset.targets)\n",
        "    dataset_test            = torchvision.datasets.CIFAR10(dir_data, transform=transform, train=False, download=True)\n",
        "    dataset_test.data       = np.array(dataset_test.data)\n",
        "    dataset_test.targets    = np.array(dataset_test.targets)\n",
        "\n",
        "elif data_name == 'CELEBA':\n",
        "    dataset = torchvision.datasets.CelebA(dir_data, transform=transform, download=True)\n",
        "   \n",
        "if data_name == 'MNIST' or data_name == 'CIFAR10': \n",
        "    if not data_use_all:\n",
        "        idx_label               = (dataset.targets==data_label_subset)\n",
        "        dataset.data            = dataset.data[idx_label]\n",
        "        dataset.targets         = dataset.targets[idx_label]\n",
        "        \n",
        "        idx_label               = (dataset_test.targets==data_label_subset)\n",
        "        dataset_test.data       = dataset_test.data[idx_label]\n",
        "        dataset_test.targets    = dataset_test.targets[idx_label]\n",
        "\n",
        "    num_data_real       = len(dataset)\n",
        "    number_data_real    = 5000\n",
        "    dataset.data        = dataset.data[0:number_data_real]\n",
        "    dataset.targets     = dataset.targets[0:number_data_real]\n",
        "\n",
        "dataloader      = torch.utils.data.DataLoader(dataset=dataset, batch_size=optim_size_batch*2, drop_last=True, shuffle=True)\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=optim_size_batch, drop_last=True, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# model \n",
        "# ======================================================================\n",
        "model = models.auto_encoder(\n",
        "            dim_channel=data_channel,\n",
        "            dim_feature=model_dim_feature,\n",
        "            dim_latent=model_dim_latent,\n",
        "            model_conv=model_conv, \n",
        "            activation=model_activation, \n",
        "            activation_output=model_output, \n",
        "            use_batch_norm=model_use_batch_norm, \n",
        "            use_skip=model_use_skip,   # skip connection 사용 유무\n",
        "            use_dual_input=False).to(device)\n",
        "\n",
        "energy = models.energy(\n",
        "            dim_channel=data_channel,\n",
        "            dim_feature=model_dim_feature,\n",
        "            dim_latent=model_dim_latent,\n",
        "            model_conv=model_conv,\n",
        "            activation=model_activation,\n",
        "            activation_output='identity',\n",
        "            use_batch_norm=model_use_batch_norm,\n",
        "            use_skip=False,\n",
        "            use_dual_input=False).to(device)\n",
        "        \n",
        "# ======================================================================\n",
        "# optimizer \n",
        "# ======================================================================\n",
        "if optim_option.lower() == 'sgd':\n",
        "    optim_model     = torch.optim.SGD(model.parameters(), lr=optim_lr_model)\n",
        "    optim_energy    = torch.optim.SGD(energy.parameters(), lr=optim_lr_energy)\n",
        "elif optim_option.lower() == 'adam':\n",
        "    optim_model     = torch.optim.Adam(model.parameters(), lr=optim_lr_model)\n",
        "    optim_energy    = torch.optim.Adam(energy.parameters(), lr=optim_lr_energy)\n",
        "elif optim_option.lower() == 'adamw':\n",
        "    optim_model     = torch.optim.AdamW(model.parameters(), lr=optim_lr_model)\n",
        "    optim_energy    = torch.optim.AdamW(energy.parameters(), lr=optim_lr_energy)\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optim_energy, max_lr=lr_energy, div_factor=10, final_div_factor=100, total_steps=length_epoch)\n",
        "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim_energy, length_epoch) \n",
        "\n",
        "# ======================================================================\n",
        "# evaluation \n",
        "# ======================================================================\n",
        "psnr = PeakSignalNoiseRatio().to(device)\n",
        "\n",
        "# ======================================================================\n",
        "# training \n",
        "# ======================================================================\n",
        "val_loss_model_mean     = np.zeros(optim_length_epoch)\n",
        "val_loss_model_std      = np.zeros(optim_length_epoch)\n",
        "val_loss_energy_mean    = np.zeros(optim_length_epoch)\n",
        "val_loss_energy_std     = np.zeros(optim_length_epoch)\n",
        "val_psnr_mean           = np.zeros(optim_length_epoch)\n",
        "val_psnr_std            = np.zeros(optim_length_epoch)\n",
        "val_psnr_update_mean    = np.zeros(optim_length_epoch)\n",
        "val_psnr_update_std     = np.zeros(optim_length_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   0/1000] loss(model)=0.0000001, loss(energy)=-0.0063984, psnr=6.62, psnr(update)=6.62\n",
            "[   5/1000] loss(model)=0.0212855, loss(energy)=-28946.8556055, psnr=6.62, psnr(update)=6.47\n",
            "[  10/1000] loss(model)=6.6040225, loss(energy)=-347299.8237500, psnr=6.63, psnr(update)=-7.85\n",
            "[  15/1000] loss(model)=7.9830796, loss(energy)=-412563.7850000, psnr=6.63, psnr(update)=-8.63\n",
            "[  20/1000] loss(model)=6.7440681, loss(energy)=-452799.2562500, psnr=6.62, psnr(update)=-7.71\n",
            "[  25/1000] loss(model)=5.7613917, loss(energy)=-480532.0337500, psnr=6.62, psnr(update)=-6.75\n",
            "[  30/1000] loss(model)=2.9617092, loss(energy)=-195790.2062500, psnr=7.87, psnr(update)=-4.22\n",
            "[  35/1000] loss(model)=2.9777401, loss(energy)=-263259.4350000, psnr=7.90, psnr(update)=-3.96\n",
            "[  40/1000] loss(model)=3.3715275, loss(energy)=-320598.0637500, psnr=7.86, psnr(update)=-4.26\n",
            "[  45/1000] loss(model)=3.4433792, loss(energy)=-340571.2587500, psnr=7.85, psnr(update)=-4.33\n",
            "[  50/1000] loss(model)=3.4823682, loss(energy)=-353920.0912500, psnr=7.87, psnr(update)=-4.38\n",
            "[  55/1000] loss(model)=3.4398336, loss(energy)=-364159.7300000, psnr=7.89, psnr(update)=-4.34\n",
            "[  60/1000] loss(model)=3.3441603, loss(energy)=-363770.1775000, psnr=7.85, psnr(update)=-4.18\n",
            "[  65/1000] loss(model)=3.2585994, loss(energy)=-370744.1012500, psnr=7.87, psnr(update)=-4.12\n",
            "[  70/1000] loss(model)=3.1334491, loss(energy)=-370586.8475000, psnr=7.86, psnr(update)=-3.89\n",
            "[  75/1000] loss(model)=3.1452101, loss(energy)=-374236.0162500, psnr=7.87, psnr(update)=-3.96\n",
            "[  80/1000] loss(model)=3.0484192, loss(energy)=-377566.5937500, psnr=7.87, psnr(update)=-3.80\n",
            "[  85/1000] loss(model)=3.0002077, loss(energy)=-377121.9300000, psnr=7.87, psnr(update)=-3.70\n",
            "[  90/1000] loss(model)=3.0725910, loss(energy)=-377927.6350000, psnr=7.87, psnr(update)=-3.76\n",
            "[  95/1000] loss(model)=2.9240135, loss(energy)=-379465.9412500, psnr=7.88, psnr(update)=-3.46\n",
            "[ 100/1000] loss(model)=2.8686108, loss(energy)=-379046.5450000, psnr=7.86, psnr(update)=-3.36\n",
            "[ 105/1000] loss(model)=2.8469608, loss(energy)=-380949.3837500, psnr=7.87, psnr(update)=-3.34\n",
            "[ 110/1000] loss(model)=2.8245714, loss(energy)=-381047.9475000, psnr=7.87, psnr(update)=-3.09\n",
            "[ 115/1000] loss(model)=2.8303103, loss(energy)=-381512.0625000, psnr=7.86, psnr(update)=-3.33\n",
            "[ 120/1000] loss(model)=2.6855367, loss(energy)=-382338.8650000, psnr=7.88, psnr(update)=-3.07\n",
            "[ 125/1000] loss(model)=2.6590352, loss(energy)=-384485.6862500, psnr=7.87, psnr(update)=-3.06\n",
            "[ 130/1000] loss(model)=2.6855467, loss(energy)=-385163.9750000, psnr=7.88, psnr(update)=-3.14\n",
            "[ 135/1000] loss(model)=2.6413358, loss(energy)=-384293.8625000, psnr=7.87, psnr(update)=-3.05\n",
            "[ 140/1000] loss(model)=2.6368156, loss(energy)=-383409.3400000, psnr=7.86, psnr(update)=-3.03\n",
            "[ 145/1000] loss(model)=2.6645520, loss(energy)=-385613.9675000, psnr=7.88, psnr(update)=-3.17\n",
            "[ 150/1000] loss(model)=2.5662200, loss(energy)=-383812.7987500, psnr=7.87, psnr(update)=-3.01\n",
            "[ 155/1000] loss(model)=2.4897724, loss(energy)=-382091.9462500, psnr=7.86, psnr(update)=-2.90\n",
            "[ 160/1000] loss(model)=2.4489995, loss(energy)=-384268.0112500, psnr=7.89, psnr(update)=-2.81\n",
            "[ 165/1000] loss(model)=2.3226712, loss(energy)=-382718.3387500, psnr=7.88, psnr(update)=-2.52\n",
            "[ 170/1000] loss(model)=2.4008133, loss(energy)=-385548.8012500, psnr=7.89, psnr(update)=-2.68\n",
            "[ 175/1000] loss(model)=2.4000338, loss(energy)=-384410.7275000, psnr=7.88, psnr(update)=-2.63\n",
            "[ 180/1000] loss(model)=2.4536254, loss(energy)=-384567.8325000, psnr=7.87, psnr(update)=-2.80\n",
            "[ 185/1000] loss(model)=2.4519972, loss(energy)=-384775.2375000, psnr=7.87, psnr(update)=-2.78\n",
            "[ 190/1000] loss(model)=2.2962864, loss(energy)=-389062.7150000, psnr=7.90, psnr(update)=-2.45\n",
            "[ 195/1000] loss(model)=2.2905022, loss(energy)=-384975.2012500, psnr=7.87, psnr(update)=-2.43\n",
            "[ 200/1000] loss(model)=2.2864960, loss(energy)=-385828.9762500, psnr=7.87, psnr(update)=-2.40\n",
            "[ 205/1000] loss(model)=2.3024948, loss(energy)=-386167.1500000, psnr=7.87, psnr(update)=-2.45\n",
            "[ 210/1000] loss(model)=2.3260264, loss(energy)=-386526.7775000, psnr=7.87, psnr(update)=-2.50\n",
            "[ 215/1000] loss(model)=2.2451683, loss(energy)=-386633.1787500, psnr=7.87, psnr(update)=-2.31\n",
            "[ 220/1000] loss(model)=2.2622204, loss(energy)=-386749.5600000, psnr=7.86, psnr(update)=-2.32\n",
            "[ 225/1000] loss(model)=2.2755204, loss(energy)=-386329.9687500, psnr=7.86, psnr(update)=-2.35\n",
            "[ 230/1000] loss(model)=2.2825149, loss(energy)=-386167.5212500, psnr=7.86, psnr(update)=-2.39\n",
            "[ 235/1000] loss(model)=2.3155125, loss(energy)=-387822.9287500, psnr=7.88, psnr(update)=-2.48\n",
            "[ 240/1000] loss(model)=2.3178953, loss(energy)=-387401.1725000, psnr=7.87, psnr(update)=-2.49\n",
            "[ 245/1000] loss(model)=2.3156016, loss(energy)=-387593.2750000, psnr=7.87, psnr(update)=-2.47\n",
            "[ 250/1000] loss(model)=2.2719259, loss(energy)=-388740.8650000, psnr=7.88, psnr(update)=-2.39\n",
            "[ 255/1000] loss(model)=2.2482269, loss(energy)=-385949.5375000, psnr=7.85, psnr(update)=-2.33\n",
            "[ 260/1000] loss(model)=2.2823537, loss(energy)=-386406.5712500, psnr=7.85, psnr(update)=-2.43\n",
            "[ 265/1000] loss(model)=2.2882390, loss(energy)=-386889.7812500, psnr=7.85, psnr(update)=-2.44\n",
            "[ 270/1000] loss(model)=2.2630202, loss(energy)=-387423.5900000, psnr=7.86, psnr(update)=-2.37\n",
            "[ 275/1000] loss(model)=2.3027913, loss(energy)=-390839.6712500, psnr=7.89, psnr(update)=-2.45\n",
            "[ 280/1000] loss(model)=2.2658159, loss(energy)=-388928.7787500, psnr=7.87, psnr(update)=-2.40\n",
            "[ 285/1000] loss(model)=2.2755889, loss(energy)=-389228.5175000, psnr=7.88, psnr(update)=-2.45\n",
            "[ 290/1000] loss(model)=2.2613991, loss(energy)=-388245.3300000, psnr=7.87, psnr(update)=-2.49\n",
            "[ 295/1000] loss(model)=2.3036632, loss(energy)=-387708.0475000, psnr=7.87, psnr(update)=-2.60\n",
            "[ 300/1000] loss(model)=2.2993378, loss(energy)=-389086.7437500, psnr=7.87, psnr(update)=-2.60\n",
            "[ 305/1000] loss(model)=2.2458771, loss(energy)=-387183.4887500, psnr=7.86, psnr(update)=-2.46\n",
            "[ 310/1000] loss(model)=2.3051682, loss(energy)=-388735.9912500, psnr=7.87, psnr(update)=-2.63\n",
            "[ 315/1000] loss(model)=2.3386245, loss(energy)=-388796.8462500, psnr=7.87, psnr(update)=-2.67\n",
            "[ 320/1000] loss(model)=2.2716844, loss(energy)=-386969.0325000, psnr=7.86, psnr(update)=-2.51\n",
            "[ 325/1000] loss(model)=2.2555166, loss(energy)=-386692.4725000, psnr=7.86, psnr(update)=-2.49\n",
            "[ 330/1000] loss(model)=2.2419467, loss(energy)=-388282.3537500, psnr=7.87, psnr(update)=-2.45\n",
            "[ 335/1000] loss(model)=2.2882202, loss(energy)=-389767.5012500, psnr=7.89, psnr(update)=-2.57\n",
            "[ 340/1000] loss(model)=2.3004990, loss(energy)=-390315.5350000, psnr=7.88, psnr(update)=-2.62\n",
            "[ 345/1000] loss(model)=2.2630843, loss(energy)=-386230.1725000, psnr=7.88, psnr(update)=-2.54\n",
            "[ 350/1000] loss(model)=2.2527418, loss(energy)=-387281.2300000, psnr=7.87, psnr(update)=-2.50\n",
            "[ 355/1000] loss(model)=2.3355839, loss(energy)=-386019.3637500, psnr=7.88, psnr(update)=-2.72\n",
            "[ 360/1000] loss(model)=2.2991251, loss(energy)=-383933.1575000, psnr=7.87, psnr(update)=-2.67\n",
            "[ 365/1000] loss(model)=2.2189112, loss(energy)=-384244.5412500, psnr=7.87, psnr(update)=-2.42\n",
            "[ 370/1000] loss(model)=2.1775630, loss(energy)=-385815.3937500, psnr=7.88, psnr(update)=-2.40\n",
            "[ 375/1000] loss(model)=2.1868599, loss(energy)=-386183.3662500, psnr=7.87, psnr(update)=-2.42\n",
            "[ 380/1000] loss(model)=2.1821392, loss(energy)=-386258.0200000, psnr=7.86, psnr(update)=-2.40\n",
            "[ 385/1000] loss(model)=2.2151521, loss(energy)=-385611.9262500, psnr=7.85, psnr(update)=-2.45\n",
            "[ 390/1000] loss(model)=2.2409822, loss(energy)=-388692.2762500, psnr=7.88, psnr(update)=-2.53\n",
            "[ 395/1000] loss(model)=2.2637878, loss(energy)=-389713.4325000, psnr=7.90, psnr(update)=-2.57\n",
            "[ 400/1000] loss(model)=2.2511726, loss(energy)=-387385.4625000, psnr=7.87, psnr(update)=-2.55\n",
            "[ 405/1000] loss(model)=2.2504332, loss(energy)=-387722.7087500, psnr=7.87, psnr(update)=-2.55\n",
            "[ 410/1000] loss(model)=2.2426179, loss(energy)=-387626.2112500, psnr=7.87, psnr(update)=-2.54\n",
            "[ 415/1000] loss(model)=2.2241914, loss(energy)=-386036.2650000, psnr=7.86, psnr(update)=-2.45\n",
            "[ 420/1000] loss(model)=2.2534903, loss(energy)=-389083.9212500, psnr=7.88, psnr(update)=-2.53\n",
            "[ 425/1000] loss(model)=2.2587803, loss(energy)=-388629.2437500, psnr=7.87, psnr(update)=-2.61\n",
            "[ 430/1000] loss(model)=2.2812746, loss(energy)=-388266.6937500, psnr=7.87, psnr(update)=-2.64\n",
            "[ 435/1000] loss(model)=2.3230727, loss(energy)=-383436.6450000, psnr=7.86, psnr(update)=-2.78\n",
            "[ 440/1000] loss(model)=2.4146318, loss(energy)=-382284.5750000, psnr=7.89, psnr(update)=-2.87\n",
            "[ 445/1000] loss(model)=2.2522142, loss(energy)=-387128.4837500, psnr=7.87, psnr(update)=-2.48\n",
            "[ 450/1000] loss(model)=2.2896833, loss(energy)=-388819.3337500, psnr=7.87, psnr(update)=-2.58\n",
            "[ 455/1000] loss(model)=2.5986057, loss(energy)=-376465.7162500, psnr=7.84, psnr(update)=-3.10\n",
            "[ 460/1000] loss(model)=2.7290754, loss(energy)=-383668.3337500, psnr=7.86, psnr(update)=-3.27\n",
            "[ 465/1000] loss(model)=2.2889732, loss(energy)=-385583.9887500, psnr=7.86, psnr(update)=-2.60\n",
            "[ 470/1000] loss(model)=2.5981348, loss(energy)=-385949.2850000, psnr=7.86, psnr(update)=-3.07\n",
            "[ 475/1000] loss(model)=2.5045525, loss(energy)=-386228.3162500, psnr=7.85, psnr(update)=-2.81\n",
            "[ 480/1000] loss(model)=2.4937379, loss(energy)=-388865.2912500, psnr=7.87, psnr(update)=-3.01\n",
            "[ 485/1000] loss(model)=2.2538544, loss(energy)=-389760.0175000, psnr=7.88, psnr(update)=-2.50\n",
            "[ 490/1000] loss(model)=2.3228385, loss(energy)=-392131.7750000, psnr=7.90, psnr(update)=-2.62\n",
            "[ 495/1000] loss(model)=2.3002885, loss(energy)=-388106.8787500, psnr=7.86, psnr(update)=-2.56\n",
            "[ 500/1000] loss(model)=2.2197295, loss(energy)=-390953.4575000, psnr=7.89, psnr(update)=-2.42\n",
            "[ 505/1000] loss(model)=2.2689166, loss(energy)=-390988.7912500, psnr=7.88, psnr(update)=-2.54\n",
            "[ 510/1000] loss(model)=2.2581309, loss(energy)=-390843.0762500, psnr=7.88, psnr(update)=-2.52\n",
            "[ 515/1000] loss(model)=2.2412375, loss(energy)=-389770.3175000, psnr=7.86, psnr(update)=-2.49\n",
            "[ 520/1000] loss(model)=2.2815906, loss(energy)=-390059.5162500, psnr=7.87, psnr(update)=-2.67\n",
            "[ 525/1000] loss(model)=2.4969500, loss(energy)=-391421.6150000, psnr=7.89, psnr(update)=-2.84\n",
            "[ 530/1000] loss(model)=2.3898820, loss(energy)=-389749.5300000, psnr=7.87, psnr(update)=-2.84\n",
            "[ 535/1000] loss(model)=2.3746197, loss(energy)=-389580.1925000, psnr=7.88, psnr(update)=-2.80\n",
            "[ 540/1000] loss(model)=3.0645781, loss(energy)=-382891.6812500, psnr=7.88, psnr(update)=-3.88\n",
            "[ 545/1000] loss(model)=2.2762986, loss(energy)=-386539.3425000, psnr=7.87, psnr(update)=-2.57\n",
            "[ 550/1000] loss(model)=2.2143900, loss(energy)=-389262.4450000, psnr=7.88, psnr(update)=-2.43\n",
            "[ 555/1000] loss(model)=2.3043308, loss(energy)=-388070.7800000, psnr=7.86, psnr(update)=-2.50\n",
            "[ 560/1000] loss(model)=2.1700256, loss(energy)=-385453.2150000, psnr=7.83, psnr(update)=-2.25\n",
            "[ 565/1000] loss(model)=2.2569244, loss(energy)=-388674.4737500, psnr=7.87, psnr(update)=-2.48\n",
            "[ 570/1000] loss(model)=2.2188276, loss(energy)=-389017.0062500, psnr=7.87, psnr(update)=-2.41\n",
            "[ 575/1000] loss(model)=2.3004067, loss(energy)=-386122.4762500, psnr=7.88, psnr(update)=-2.52\n",
            "[ 580/1000] loss(model)=2.2877292, loss(energy)=-389323.4887500, psnr=7.89, psnr(update)=-2.67\n",
            "[ 585/1000] loss(model)=2.2331854, loss(energy)=-388854.8637500, psnr=7.88, psnr(update)=-2.50\n",
            "[ 590/1000] loss(model)=2.2198630, loss(energy)=-387037.3587500, psnr=7.85, psnr(update)=-2.38\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_37443/273351619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mvalue_psnr\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mvalue_psnr_update\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_full_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_reduce_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# calculate batch state and compute batch value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/image/psnr.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;34m\"\"\"Update state with predictions and targets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0msum_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_psnr_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/functional/image/psnr.py\u001b[0m in \u001b[0;36m_psnr_update\u001b[0;34m(preds, target, dim)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msum_squared_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mn_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "energy.train()\n",
        "\n",
        "for i in range(optim_length_epoch):\n",
        "    val_loss_model  = []\n",
        "    val_loss_energy = []\n",
        "    val_psnr        = []\n",
        "    val_psnr_update = []\n",
        "\n",
        "    for j, (image, _) in enumerate(dataloader):\n",
        "        data, real  = torch.split(image, optim_size_batch, dim=0)\n",
        "        \n",
        "        noise       = torch.randn_like(data)\n",
        "        data_noise  = data + data_noise_sigma * noise\n",
        "     \n",
        "        data        = data.to(device) \n",
        "        real        = real.to(device) \n",
        "        data_noise  = data_noise.to(device)\n",
        "        \n",
        "        # -------------------------------------------------------------------\n",
        "        # predictions\n",
        "        # -------------------------------------------------------------------         \n",
        "        pred, latent = model(data_noise) # auto encoder # z는 encoder의 output\n",
        "        \n",
        "        # -------------------------------------------------------------------\n",
        "        # interpolation\n",
        "        # -------------------------------------------------------------------         \n",
        "        alpha   = torch.rand(optim_size_batch, 1, 1, 1)\n",
        "        alpha   = alpha.expand_as(real).to(device)\n",
        "        interp  = alpha * real.data + (1 - alpha) * pred.data\n",
        "        interp  = Parameter(interp, requires_grad=True)\n",
        "\n",
        "        # -------------------------------------------------------------------\n",
        "        # predictions\n",
        "        # -------------------------------------------------------------------\n",
        "        energy_positive = energy(real)        \n",
        "        energy_negative = energy(pred.detach())        \n",
        "        energy_interp   = energy(interp)\n",
        "       \n",
        "        # -------------------------------------------------------------------\n",
        "        # update energy model \n",
        "        # -------------------------------------------------------------------         \n",
        "        optim_energy.zero_grad()\n",
        "        loss_positive   = losses.compute_loss_positive(energy_negative, energy_positive)\n",
        "        loss_gradient   = losses.compute_gradient_penalty(interp, energy_interp)\n",
        "        loss_energy     = loss_positive + optim_weight_gradient * loss_gradient\n",
        "        loss_energy.backward()\n",
        "        optim_energy.step()\n",
        "    \n",
        "        # -------------------------------------------------------------------\n",
        "        # update input fake \n",
        "        # -------------------------------------------------------------------\n",
        "        pred_update = Parameter(pred, requires_grad=True) \n",
        "        \n",
        "        for k in range(optim_length_langevin): \n",
        "            energy_negative = energy(pred_update)\n",
        "            loss_negative   = losses.compute_loss_negative(energy_negative)\n",
        "            loss_negative.backward()\n",
        "            noise = torch.randn_like(pred_update.data)    # N(mean=0, std=1)\n",
        "            pred_update.data = pred_update.data - optim_lr_data * pred_update.grad + optim_lr_langevin * noise\n",
        "            \n",
        "            pred_update.grad.detach_()\n",
        "            pred_update.grad.zero_() \n",
        "\n",
        "       \n",
        "        '''\n",
        "        for k in range(optim_length_langevin): \n",
        "            optim_energy.zero_grad()\n",
        "            energy_positive = energy(real)        \n",
        "            energy_negative = energy(pred_update.detach())\n",
        "            energy_interp   = energy(interp)\n",
        "            loss_positive   = losses.compute_loss_positive(energy_negative, energy_positive) \n",
        "            loss_gradient   = losses.compute_gradient_penalty(interp, energy_interp)\n",
        "            loss_energy     = loss_positive + optim_weight_gradient * loss_gradient\n",
        "            loss_energy.backward()\n",
        "            optim_energy.step()\n",
        "\n",
        "            energy_negative = energy(pred_update)\n",
        "            loss_negative   = losses.compute_loss_negative(energy_negative)\n",
        "            loss_negative.backward()\n",
        "            noise = torch.randn_like(pred_update.data) # N(mean=0, std=1)\n",
        "            pred_update.data = pred_update.data - optim_lr_data * pred_update.grad + optim_lr_langevin * noise\n",
        "            \n",
        "            pred_update.grad.detach_()\n",
        "            pred_update.grad.zero_() \n",
        "        \n",
        "        optim_model.zero_grad()\n",
        "        pred, latent    = model(data_noise) \n",
        "        loss_model      = model.compute_loss(pred, data) \n",
        "        loss_model.backward()\n",
        "        optim_model.step()        \n",
        "   \n",
        "        pred_update = pred\n",
        "        '''\n",
        "        \n",
        "        \n",
        "        # -------------------------------------------------------------------\n",
        "        # update model \n",
        "        # -------------------------------------------------------------------         \n",
        "        optim_model.zero_grad()\n",
        "        pred, latent    = model(data_noise) \n",
        "        loss_model      = model.compute_loss(pred, pred_update.detach()) \n",
        "        loss_model.backward()\n",
        "        optim_model.step()        \n",
        "\n",
        "\n",
        "        value_psnr          = psnr(pred.data, data).detach().cpu().numpy().mean()\n",
        "        value_psnr_update   = psnr(pred_update.data, data).detach().cpu().numpy().mean()\n",
        "            \n",
        "        val_loss_model.append(loss_model.item()) \n",
        "        val_loss_energy.append(loss_energy.item()) \n",
        "        val_psnr.append(value_psnr)\n",
        "        val_psnr_update.append(value_psnr_update)\n",
        "    \n",
        "    if i % 50 == 0:\n",
        "        dir_log             = os.path.join(dir_work, 'log')\n",
        "        file_pred           = os.path.join(dir_log, 'image/{:03d}.png'.format(i))\n",
        "        file_pred_update    = os.path.join(dir_log, 'image/{:03d}_update.png'.format(i))\n",
        "    \n",
        "        save_image(pred.data[:25], file_pred, nrow=5, normalize=True)\n",
        "        save_image(pred_update.data[:25], file_pred_update, nrow=5, normalize=True)\n",
        "        \n",
        "    \n",
        "    val_loss_model_mean[i]  = np.mean(val_loss_model)\n",
        "    val_loss_model_std[i]   = np.std(val_loss_model)\n",
        "    val_loss_energy_mean[i] = np.mean(val_loss_energy)\n",
        "    val_loss_energy_std[i]  = np.std(val_loss_energy)\n",
        "    val_psnr_mean[i]        = np.mean(val_psnr)\n",
        "    val_psnr_std[i]         = np.std(val_psnr)\n",
        "    val_psnr_update_mean[i] = np.mean(val_psnr_update)\n",
        "    val_psnr_update_std[i]  = np.std(val_psnr_update)\n",
        "    if i % 5 == 0:\n",
        "        log = '[%4d/%4d] loss(model)=%8.7f, loss(energy)=%8.7f, psnr=%4.2f, psnr(update)=%4.2f' % (i, optim_length_epoch, \n",
        "        val_loss_model_mean[i], val_loss_energy_mean[i], val_psnr_mean[i], val_psnr_update_mean[i])\n",
        "        print(log, flush=True)\n",
        "    \n",
        "    if np.isnan(val_loss_model_mean[i]) or np.isnan(val_loss_energy_mean[i]) or val_psnr_mean[i] < 3:\n",
        "        sys.exit('error')\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# save the models\n",
        "# -------------------------------------------------------------------          \n",
        "torch.save({\n",
        "    'state_dict_model'        : model.state_dict(),\n",
        "    'state_dict_energy'       : energy.state_dict(),\n",
        "    'model_conv'              : model_conv,\n",
        "    'model_activation'        : model_activation,\n",
        "    'model_output'            : model_output,\n",
        "    'model_use_batch_norm'    : model_use_batch_norm,\n",
        "    'model_use_skip'          : model_use_skip,\n",
        "    'model_use_dual_input'    : model_use_dual_input,\n",
        "    'model_dim_feature'       : model_dim_feature,\n",
        "    'model_dim_latent'        : model_dim_latent,\n",
        "    'data_name'               : data_name,\n",
        "    'data_use_all'            : data_use_all,\n",
        "    'data_label_subset'       : data_label_subset,\n",
        "    'data_channel'            : data_channel,\n",
        "    'data_height'             : data_height,\n",
        "    'data_width'              : data_width,\n",
        "    'data_noise_sigma'        : data_noise_sigma,\n",
        "    'optim_option'            : optim_option,\n",
        "    'optim_length_epoch'      : optim_length_epoch,\n",
        "    'optim_size_batch'        : optim_size_batch,\n",
        "    'optim_lr_model'          : optim_lr_model,\n",
        "    'optim_lr_energy'         : optim_lr_energy,\n",
        "    'optim_lr_data'           : optim_lr_data,\n",
        "    'optim_lr_langevin'       : optim_lr_langevin,\n",
        "    'optim_length_langevin'   : optim_length_langevin,\n",
        "    'optim_weight_gradient'   : optim_weight_gradient,\n",
        "}, file_model)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# save the options\n",
        "# -------------------------------------------------------------------         \n",
        "with open(file_option, 'w') as f:\n",
        "    f.write('{}: {}\\n'.format('model_conv', model_conv))\n",
        "    f.write('{}: {}\\n'.format('model_activation', model_activation))\n",
        "    f.write('{}: {}\\n'.format('model_output', model_output))\n",
        "    f.write('{}: {}\\n'.format('model_use_batch_norm', model_use_batch_norm))\n",
        "    f.write('{}: {}\\n'.format('model_use_skip', model_use_skip))\n",
        "    f.write('{}: {}\\n'.format('model_use_dual_input', model_use_dual_input))\n",
        "    f.write('{}: {}\\n'.format('model_dim_feature', model_dim_feature))\n",
        "    f.write('{}: {}\\n'.format('model_dim_latent', model_dim_latent))\n",
        "    f.write('{}: {}\\n'.format('data_name', data_name))\n",
        "    f.write('{}: {}\\n'.format('data_use_all', data_use_all))\n",
        "    f.write('{}: {}\\n'.format('data_label_subset', data_label_subset))\n",
        "    f.write('{}: {}\\n'.format('data_channel', data_channel))\n",
        "    f.write('{}: {}\\n'.format('data_height', data_height))\n",
        "    f.write('{}: {}\\n'.format('data_width', data_width))\n",
        "    f.write('{}: {}\\n'.format('data_noise_sigma', data_noise_sigma))\n",
        "    f.write('{}: {}\\n'.format('optim_option', optim_option))\n",
        "    f.write('{}: {}\\n'.format('optim_length_epoch', optim_length_epoch))\n",
        "    f.write('{}: {}\\n'.format('optim_size_batch', optim_size_batch))\n",
        "    f.write('{}: {}\\n'.format('optim_lr_model', optim_lr_model))\n",
        "    f.write('{}: {}\\n'.format('optim_lr_energy', optim_lr_energy))\n",
        "    f.write('{}: {}\\n'.format('optim_lr_data', optim_lr_data))\n",
        "    f.write('{}: {}\\n'.format('optim_lr_langevin', optim_lr_langevin))\n",
        "    f.write('{}: {}\\n'.format('optim_length_langevin', optim_length_langevin))\n",
        "    f.write('{}: {}\\n'.format('optim_weight_gradient', optim_weight_gradient))\n",
        "f.close()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 1, 32, 32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# -------------------------------------------------------------------\n",
        "# save training results\n",
        "# -------------------------------------------------------------------         \n",
        "nRow    = 5 \n",
        "nCol    = 5\n",
        "fSize   = 3\n",
        "\n",
        "fig, ax = plt.subplots(nRow, nCol, figsize=(fSize * nCol, fSize * nRow))\n",
        "\n",
        "ax[0][0].set_title('loss (model)')\n",
        "ax[0][0].plot(val_loss_model_mean, color='red')\n",
        "ax[0][0].fill_between(list(range(optim_length_epoch)), val_loss_model_mean-val_loss_model_std, val_loss_model_mean+val_loss_model_std, color='blue', alpha=0.2)\n",
        "\n",
        "ax[0][1].set_title('loss (energy)')\n",
        "ax[0][1].plot(val_loss_energy_mean, color='red')\n",
        "ax[0][1].fill_between(list(range(optim_length_epoch)), val_loss_energy_mean-val_loss_energy_std, val_loss_energy_mean+val_loss_energy_std, color='blue', alpha=0.2)\n",
        "\n",
        "ax[0][2].set_title('psnr')\n",
        "ax[0][2].plot(val_psnr_mean, color='blue', label='y_0')\n",
        "ax[0][2].plot(val_psnr_update_mean, color='red', label='y_n')\n",
        "ax[0][2].legend()\n",
        "\n",
        "for i in range(nCol):\n",
        "    ax[1][i].set_title('clean')\n",
        "    ax[1][i].imshow(data.data.detach().cpu().numpy()[i])\n",
        "\n",
        "for i in range(nCol):\n",
        "    ax[2][i].set_title('noisy')\n",
        "    ax[2][i].imshow(data_noise.data.detach().cpu().numpy()[i])\n",
        "\n",
        "for i in range(nCol):\n",
        "    ax[3][i].set_title('y_0')\n",
        "    ax[3][i].imshow(pred.data.detach().cpu().numpy()[i])\n",
        "\n",
        "for i in range(nCol):\n",
        "    ax[4][i].set_title('y_n')\n",
        "    ax[4][i].imshow(pred_update.data.detach().cpu().numpy()[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.savefig(file_figure, bbox_inches='tight', dpi=300)\n",
        "plt.close(fig)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
