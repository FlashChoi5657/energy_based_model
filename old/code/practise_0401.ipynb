{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os, copy, argparse, configparser\n",
    "import sys, datetime, csv, random\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import PeakSignalNoiseRatio\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.utils import save_image\n",
    "import network_models as models\n",
    "import function_losses as losses\n",
    "# import pytorch_model_summary as mosum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# take options \n",
    "# ======================================================================\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dir_work\", type=str, default='/nas/users/minhyeok/energy_based_model')\n",
    "parser.add_argument(\"--device_cuda\", type=int, default=0)\n",
    "\n",
    "parser.add_argument(\"--model_conv\", type=str, default='conv_double_resnet')\n",
    "parser.add_argument(\"--model_activation\", type=str, default='leakyrelu')\n",
    "parser.add_argument(\"--model_output\", type=str, default='sigmoid')\n",
    "parser.add_argument(\"--model_use_batch_norm\", type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument(\"--model_use_skip\", type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument(\"--model_use_dual_input\", type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument(\"--model_dim_feature\", type=int, default=16)\n",
    "parser.add_argument(\"--model_dim_latent\", type=int, default=100)\n",
    "\n",
    "parser.add_argument(\"--data_name\", type=str, default='CIFAR10')\n",
    "parser.add_argument(\"--data_use_all\", type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument(\"--data_label_subset\", type=int, default=5)\n",
    "parser.add_argument(\"--data_channel\", type=int, default=3)\n",
    "parser.add_argument(\"--data_height\", type=int, default=32)\n",
    "parser.add_argument(\"--data_width\", type=int, default=32)\n",
    "parser.add_argument(\"--data_noise_sigma\", type=float, default=0.5)\n",
    "\n",
    "parser.add_argument(\"--optim_option\", type=str, default='adam')\n",
    "parser.add_argument(\"--optim_length_epoch\", type=int, default=500)\n",
    "parser.add_argument(\"--optim_size_batch\", type=int, default=100)\n",
    "parser.add_argument(\"--optim_lr_model\", type=float, default=0.01)\n",
    "parser.add_argument(\"--optim_lr_energy\", type=float, default=0.01)\n",
    "parser.add_argument(\"--optim_lr_data\", type=float, default=0.01)\n",
    "parser.add_argument(\"--optim_lr_langevin\", type=float, default=0.0001)\n",
    "parser.add_argument(\"--optim_length_langevin\", type=int, default=10)\n",
    "parser.add_argument(\"--optim_weight_gradient\", type=float, default=0.0001)\n",
    "parser.add_argument(\"--optim_weight_regular\", type=float, default=0.0001)\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# assign options\n",
    "# ======================================================================\n",
    "dir_work                = args.dir_work\n",
    "device_cuda             = args.device_cuda\n",
    "\n",
    "model_conv              = args.model_conv\n",
    "model_activation        = args.model_activation\n",
    "model_output            = args.model_output\n",
    "model_use_batch_norm    = args.model_use_batch_norm\n",
    "model_use_skip          = args.model_use_skip\n",
    "model_use_dual_input    = args.model_use_dual_input\n",
    "model_dim_feature       = args.model_dim_feature\n",
    "model_dim_latent        = args.model_dim_latent\n",
    "\n",
    "data_name               = args.data_name.upper()\n",
    "data_use_all            = args.data_use_all\n",
    "data_label_subset       = args.data_label_subset \n",
    "data_channel            = args.data_channel\n",
    "data_height             = args.data_height\n",
    "data_width              = args.data_width\n",
    "data_noise_sigma        = args.data_noise_sigma\n",
    "\n",
    "optim_option            = args.optim_option\n",
    "optim_length_epoch      = args.optim_length_epoch\n",
    "optim_size_batch        = args.optim_size_batch\n",
    "optim_lr_model          = args.optim_lr_model\n",
    "optim_lr_energy         = args.optim_lr_energy\n",
    "optim_lr_data           = args.optim_lr_data\n",
    "optim_lr_langevin       = args.optim_lr_langevin\n",
    "optim_length_langevin   = args.optim_length_langevin\n",
    "optim_weight_gradient   = args.optim_weight_gradient\n",
    "optim_weight_regular    = args.optim_weight_regular\n",
    "\n",
    "# ======================================================================\n",
    "# path for the results\n",
    "# ======================================================================\n",
    "now         = datetime.datetime.now()\n",
    "date_stamp  = now.strftime('%Y_%m_%d') \n",
    "time_stamp  = now.strftime('%H_%M_%S') \n",
    "\n",
    "dir_figure  = os.path.join(dir_work, 'figure')\n",
    "dir_option  = os.path.join(dir_work, 'option')\n",
    "dir_result  = os.path.join(dir_work, 'result')\n",
    "dir_model   = os.path.join(dir_work, 'model')\n",
    "\n",
    "path_figure = os.path.join(dir_figure, data_name)\n",
    "path_option = os.path.join(dir_option, data_name)\n",
    "path_result = os.path.join(dir_result, data_name)\n",
    "path_model  = os.path.join(dir_model, data_name)\n",
    "\n",
    "date_figure = os.path.join(path_figure, date_stamp)\n",
    "date_option = os.path.join(path_option, date_stamp)\n",
    "date_result = os.path.join(path_result, date_stamp)\n",
    "date_model  = os.path.join(path_model, date_stamp)\n",
    "\n",
    "file_figure = os.path.join(date_figure, '{}.png'.format(time_stamp))\n",
    "file_option = os.path.join(date_option, '{}.ini'.format(time_stamp))\n",
    "file_result = os.path.join(date_result, '{}.csv'.format(time_stamp))\n",
    "file_model  = os.path.join(date_model, '{}.pth'.format(time_stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(f'cuda:{device_cuda}' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# ======================================================================\n",
    "# random seed\n",
    "# ======================================================================\n",
    "pl.seed_everything(0)\n",
    "\n",
    "# ======================================================================\n",
    "# dataset \n",
    "# ======================================================================\n",
    "dir_data = '/nas/users/minhyeok/dataset'\n",
    "\n",
    "transform = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.Resize([data_height, data_width]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # torchvision.transforms.Lambda(lambda t: (t - torch.mean(t)) / torch.std(t)) # mean 0, std 1\n",
    "    # torchvision.transforms.Lambda(lambda t: 2.0 * t - 1) \n",
    "])\n",
    "\n",
    "# the name of the dataset is used as upper case\n",
    "if data_name == 'MNIST':\n",
    "    dataset         = torchvision.datasets.MNIST(dir_data, transform=transform, train=True, download=True)\n",
    "    dataset_test    = torchvision.datasets.MNIST(dir_data, transform=transform, train=False, download=True)\n",
    "\n",
    "elif data_name == 'CIFAR10':\n",
    "    dataset                 = torchvision.datasets.CIFAR10(dir_data, transform=transform, train=True, download=True)\n",
    "    dataset.data            = np.array(dataset.data)\n",
    "    dataset.targets         = np.array(dataset.targets)\n",
    "    dataset_test            = torchvision.datasets.CIFAR10(dir_data, transform=transform, train=False, download=True)\n",
    "    dataset_test.data       = np.array(dataset_test.data)\n",
    "    dataset_test.targets    = np.array(dataset_test.targets)\n",
    "\n",
    "elif data_name == 'CELEBA':\n",
    "    dataset = torchvision.datasets.CelebA(dir_data, transform=transform, download=True)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    dataset, dataset_test = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "   \n",
    "if data_name == 'MNIST' or data_name == 'CIFAR10': \n",
    "    if not data_use_all:\n",
    "        idx_label               = (dataset.targets==data_label_subset)\n",
    "        dataset.data            = dataset.data[idx_label]\n",
    "        dataset.targets         = dataset.targets[idx_label]\n",
    "        \n",
    "        idx_label               = (dataset_test.targets==data_label_subset)\n",
    "        dataset_test.data       = dataset_test.data[idx_label]\n",
    "        dataset_test.targets    = dataset_test.targets[idx_label]\n",
    "\n",
    "    num_data_real       = len(dataset)\n",
    "    number_data_real    = 5000\n",
    "    dataset.data        = dataset.data[0:number_data_real]\n",
    "    dataset.targets     = dataset.targets[0:number_data_real]\n",
    "\n",
    "dataloader      = torch.utils.data.DataLoader(dataset=dataset, batch_size=optim_size_batch*2, drop_last=True, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=optim_size_batch, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.auto_encoder2(\n",
    "            dim_channel=data_channel,\n",
    "            dim_feature=model_dim_feature,\n",
    "            dim_latent=model_dim_latent,\n",
    "            use_batch_norm=model_use_batch_norm, \n",
    "            activation_output=model_output).to(device)\n",
    "'''\n",
    "energy = models.energy2(\n",
    "            dim_channel=data_channel,\n",
    "            dim_feature=model_dim_feature,\n",
    "            use_batch_norm=model_use_batch_norm,\n",
    "            use_dual_input=model_use_dual_input).to(device)\n",
    "'''\n",
    "\n",
    "energy = models.energy2(\n",
    "            dim_channel=data_channel,\n",
    "            dim_feature=model_dim_feature,\n",
    "            use_batch_norm=False,\n",
    "            use_dual_input=model_use_dual_input).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optim_option.lower() == 'sgd':\n",
    "    optim_model     = torch.optim.SGD(model.parameters(), lr=optim_lr_model)\n",
    "    optim_energy    = torch.optim.SGD(energy.parameters(), lr=optim_lr_energy)\n",
    "elif optim_option.lower() == 'adam':\n",
    "    optim_model     = torch.optim.Adam(model.parameters(), lr=optim_lr_model)\n",
    "    optim_energy    = torch.optim.Adam(energy.parameters(), lr=optim_lr_energy)\n",
    "elif optim_option.lower() == 'adamw':\n",
    "    optim_model     = torch.optim.AdamW(model.parameters(), lr=optim_lr_model)\n",
    "    optim_energy    = torch.optim.AdamW(energy.parameters(), lr=optim_lr_energy)\n",
    "\n",
    "\n",
    "scheduler_model     = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_model, factor=0.0001, patience=10, mode='min')\n",
    "scheduler_energy    = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_energy, factor=0.0001, patience=10, mode='min')\n",
    "\n",
    "# ======================================================================\n",
    "# evaluation \n",
    "# ======================================================================\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# ======================================================================\n",
    "# training \n",
    "# ======================================================================\n",
    "val_loss_model_mean     = np.zeros(optim_length_epoch)\n",
    "val_loss_model_std      = np.zeros(optim_length_epoch)\n",
    "val_loss_energy_mean    = np.zeros(optim_length_epoch)\n",
    "val_loss_energy_std     = np.zeros(optim_length_epoch)\n",
    "val_psnr_mean           = np.zeros(optim_length_epoch)\n",
    "val_psnr_std            = np.zeros(optim_length_epoch)\n",
    "val_psnr_update_mean    = np.zeros(optim_length_epoch)\n",
    "val_psnr_update_std     = np.zeros(optim_length_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46210/417594028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0malpha\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim_size_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0malpha\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0minterp\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0minterp\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "energy.train()\n",
    "\n",
    "for i in range(optim_length_epoch):\n",
    "    val_loss_model  = []\n",
    "    val_loss_energy = []\n",
    "    val_psnr        = []\n",
    "    val_psnr_update = []\n",
    "\n",
    "    for j, (image, _) in enumerate(dataloader):\n",
    "        data, real  = torch.split(image, optim_size_batch, dim=0)\n",
    "        \n",
    "        noise       = torch.randn_like(data)\n",
    "        data_noise  = data + data_noise_sigma * noise\n",
    "        \n",
    "        noise       = torch.randn_like(data)\n",
    "        real_noise  = real + data_noise_sigma * noise\n",
    "     \n",
    "        data        = data.to(device) \n",
    "        real        = real.to(device) \n",
    "        data_noise  = data_noise.to(device)\n",
    "        real_noise  = real_noise.to(device)\n",
    "        \n",
    "        # -------------------------------------------------------------------\n",
    "        # predictions\n",
    "        # -------------------------------------------------------------------         \n",
    "        pred, mu, log_var, z = model(data_noise)\n",
    "         \n",
    "        # -------------------------------------------------------------------\n",
    "        # interpolation\n",
    "        # -------------------------------------------------------------------         \n",
    "        alpha   = torch.rand(optim_size_batch, 1, 1, 1)\n",
    "        alpha   = alpha.expand_as(real).to(device)\n",
    "        interp  = alpha * real.data + (1 - alpha) * pred.data\n",
    "        interp  = Parameter(interp, requires_grad=True)\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # predictions\n",
    "        # -------------------------------------------------------------------\n",
    "        if model_use_dual_input:\n",
    "            energy_positive = energy(real_noise, real)        \n",
    "            energy_negative = energy(data_noise, pred)        \n",
    "            energy_interp   = energy(interp, interp)\n",
    "        else:\n",
    "            energy_positive = energy(real)        \n",
    "            energy_negative = energy(pred)        \n",
    "            energy_interp   = energy(interp)\n",
    "        \n",
    "        # -------------------------------------------------------------------\n",
    "        # update energy model \n",
    "        # -------------------------------------------------------------------         \n",
    "        optim_energy.zero_grad()\n",
    "        loss_positive   = energy.compute_loss_positive(energy_negative, energy_positive)\n",
    "        loss_gradient   = losses.compute_gradient_penalty(interp, energy_interp)\n",
    "        loss_energy     = loss_positive + optim_weight_gradient * loss_gradient\n",
    "        loss_energy.backward()\n",
    "        optim_energy.step()\n",
    "        scheduler_energy.step(loss_energy)\n",
    "         \n",
    "        # -------------------------------------------------------------------\n",
    "        # update input fake \n",
    "        # -------------------------------------------------------------------\n",
    "        pred_update = Parameter(pred, requires_grad=True) \n",
    "        \n",
    "        for k in range(optim_length_langevin): \n",
    "\n",
    "            if model_use_dual_input:\n",
    "                energy_negative = energy(data_noise, pred_update)\n",
    "            else:\n",
    "                energy_negative = energy(pred_update)\n",
    "                \n",
    "            loss_negative = energy.compute_loss_negative(energy_negative)\n",
    "            loss_negative.backward()\n",
    "            noise = torch.randn_like(pred_update.data)    # N(mean=0, std=1)\n",
    "            pred_update.data = pred_update.data - optim_lr_data * pred_update.grad + optim_lr_langevin * noise\n",
    "            pred_update.grad.detach_()\n",
    "            pred_update.grad.zero_() \n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # update model \n",
    "        # -------------------------------------------------------------------         \n",
    "        optim_model.zero_grad()\n",
    "        pred, mu, log_var, z = model(data_noise) \n",
    "        loss_model, loss_data, loss_regular = model.compute_loss(pred, pred_update.detach(), mu, log_var, optim_weight_regular) \n",
    "        loss_model.backward()\n",
    "        optim_model.step()        \n",
    "        scheduler_model.step(loss_model)\n",
    "\n",
    "        value_psnr          = psnr(pred.data, data).detach().cpu().numpy().mean()\n",
    "        value_psnr_update   = psnr(pred_update.data, data).detach().cpu().numpy().mean()\n",
    "            \n",
    "        val_loss_model.append(loss_model.item()) \n",
    "        val_loss_energy.append(loss_energy.item()) \n",
    "        val_psnr.append(value_psnr)\n",
    "        val_psnr_update.append(value_psnr_update)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        dir_log             = os.path.join(dir_work, 'log')\n",
    "        file_pred           = os.path.join(dir_log, 'image/pred.png')\n",
    "        file_pred_update    = os.path.join(dir_log, 'image/pred_update.png')\n",
    "        # file_pred           = os.path.join(dir_log, 'image/{:03d}.png'.format(i))\n",
    "        # file_pred_update    = os.path.join(dir_log, 'image/{:03d}_update.png'.format(i))\n",
    "    \n",
    "        save_image(pred.data[:25], file_pred, nrow=5, normalize=True)\n",
    "        save_image(pred_update.data[:25], file_pred_update, nrow=5, normalize=True)\n",
    "        \n",
    "    \n",
    "    val_loss_model_mean[i]  = np.mean(val_loss_model)\n",
    "    val_loss_model_std[i]   = np.std(val_loss_model)\n",
    "    val_loss_energy_mean[i] = np.mean(val_loss_energy)\n",
    "    val_loss_energy_std[i]  = np.std(val_loss_energy)\n",
    "    val_psnr_mean[i]        = np.mean(val_psnr)\n",
    "    val_psnr_std[i]         = np.std(val_psnr)\n",
    "    val_psnr_update_mean[i] = np.mean(val_psnr_update)\n",
    "    val_psnr_update_std[i]  = np.std(val_psnr_update)\n",
    "\n",
    "    log = '[%4d/%4d] loss(model)=%8.7f, loss(energy)=%8.7f, psnr=%4.2f, psnr(update)=%4.2f' % (i, optim_length_epoch, val_loss_model_mean[i], val_loss_energy_mean[i], val_psnr_mean[i], val_psnr_update_mean[i])\n",
    "    print(log, flush=True)\n",
    "    \n",
    "    if np.isnan(val_loss_model_mean[i]) or np.isnan(val_loss_energy_mean[i]) or val_psnr_mean[i] < 3:\n",
    "        sys.exit('error')\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# save the models\n",
    "# -------------------------------------------------------------------          \n",
    "torch.save({\n",
    "    'state_dict_model'      : model.state_dict(),\n",
    "    'state_dict_energy'     : energy.state_dict(),\n",
    "    'model_conv'            : model_conv,\n",
    "    'model_activation'      : model_activation,\n",
    "    'model_output'          : model_output,\n",
    "    'model_use_batch_norm'  : model_use_batch_norm,\n",
    "    'model_use_skip'        : model_use_skip,\n",
    "    'model_use_dual_input'  : model_use_dual_input,\n",
    "    'model_dim_feature'     : model_dim_feature,\n",
    "    'model_dim_latent'      : model_dim_latent,\n",
    "    'data_name'             : data_name,\n",
    "    'data_use_all'          : data_use_all,\n",
    "    'data_label_subset'     : data_label_subset,\n",
    "    'data_channel'          : data_channel,\n",
    "    'data_height'           : data_height,\n",
    "    'data_width'            : data_width,\n",
    "    'data_noise_sigma'      : data_noise_sigma,\n",
    "    'optim_option'          : optim_option,\n",
    "    'optim_length_epoch'    : optim_length_epoch,\n",
    "    'optim_size_batch'      : optim_size_batch,\n",
    "    'optim_lr_model'        : optim_lr_model,\n",
    "    'optim_lr_energy'       : optim_lr_energy,\n",
    "    'optim_lr_data'         : optim_lr_data,\n",
    "    'optim_lr_langevin'     : optim_lr_langevin,\n",
    "    'optim_length_langevin' : optim_length_langevin,\n",
    "    'optim_weight_gradient' : optim_weight_gradient,\n",
    "    'optim_weight_regular'  : optim_weight_regular,\n",
    "}, file_model)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# save the options\n",
    "# -------------------------------------------------------------------         \n",
    "with open(file_option, 'w') as f:\n",
    "    f.write('{}: {}\\n'.format('model_conv', model_conv))\n",
    "    f.write('{}: {}\\n'.format('model_activation', model_activation))\n",
    "    f.write('{}: {}\\n'.format('model_output', model_output))\n",
    "    f.write('{}: {}\\n'.format('model_use_batch_norm', model_use_batch_norm))\n",
    "    f.write('{}: {}\\n'.format('model_use_skip', model_use_skip))\n",
    "    f.write('{}: {}\\n'.format('model_use_dual_input', model_use_dual_input))\n",
    "    f.write('{}: {}\\n'.format('model_dim_feature', model_dim_feature))\n",
    "    f.write('{}: {}\\n'.format('model_dim_latent', model_dim_latent))\n",
    "    f.write('{}: {}\\n'.format('data_name', data_name))\n",
    "    f.write('{}: {}\\n'.format('data_use_all', data_use_all))\n",
    "    f.write('{}: {}\\n'.format('data_label_subset', data_label_subset))\n",
    "    f.write('{}: {}\\n'.format('data_channel', data_channel))\n",
    "    f.write('{}: {}\\n'.format('data_height', data_height))\n",
    "    f.write('{}: {}\\n'.format('data_width', data_width))\n",
    "    f.write('{}: {}\\n'.format('data_noise_sigma', data_noise_sigma))\n",
    "    f.write('{}: {}\\n'.format('optim_option', optim_option))\n",
    "    f.write('{}: {}\\n'.format('optim_length_epoch', optim_length_epoch))\n",
    "    f.write('{}: {}\\n'.format('optim_size_batch', optim_size_batch))\n",
    "    f.write('{}: {}\\n'.format('optim_lr_model', optim_lr_model))\n",
    "    f.write('{}: {}\\n'.format('optim_lr_energy', optim_lr_energy))\n",
    "    f.write('{}: {}\\n'.format('optim_lr_data', optim_lr_data))\n",
    "    f.write('{}: {}\\n'.format('optim_lr_langevin', optim_lr_langevin))\n",
    "    f.write('{}: {}\\n'.format('optim_length_langevin', optim_length_langevin))\n",
    "    f.write('{}: {}\\n'.format('optim_weight_gradient', optim_weight_gradient))\n",
    "    f.write('{}: {}\\n'.format('optim_weight_regular', optim_weight_regular))\n",
    "f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# save training results\n",
    "# -------------------------------------------------------------------         \n",
    "data        = data.detach().cpu().numpy().squeeze()\n",
    "data_noise  = data_noise.detach().cpu().numpy().squeeze()\n",
    "pred        = pred.detach().cpu().numpy().squeeze()\n",
    "pred_update = pred_update.detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRow    = 5 \n",
    "nCol    = 5\n",
    "fSize   = 3\n",
    "\n",
    "fig, ax = plt.subplots(nRow, nCol, figsize=(fSize * nCol, fSize * nRow))\n",
    "\n",
    "ax[0][0].set_title('loss (model)')\n",
    "ax[0][0].plot(val_loss_model_mean, color='red')\n",
    "ax[0][0].fill_between(list(range(optim_length_epoch)), val_loss_model_mean-val_loss_model_std, val_loss_model_mean+val_loss_model_std, color='blue', alpha=0.2)\n",
    "\n",
    "ax[0][1].set_title('loss (energy)')\n",
    "ax[0][1].plot(val_loss_energy_mean, color='red')\n",
    "ax[0][1].fill_between(list(range(optim_length_epoch)), val_loss_energy_mean-val_loss_energy_std, val_loss_energy_mean+val_loss_energy_std, color='blue', alpha=0.2)\n",
    "\n",
    "ax[0][2].set_title('psnr')\n",
    "ax[0][2].plot(val_psnr_mean, color='blue', label='y_0')\n",
    "ax[0][2].plot(val_psnr_update_mean, color='red', label='y_n')\n",
    "ax[0][2].legend()\n",
    "\n",
    "for i in range(nCol):\n",
    "    ax[1][i].set_title('clean')\n",
    "    ax[1][i].imshow(data[i])\n",
    "\n",
    "for i in range(nCol):\n",
    "    ax[2][i].set_title('noisy')\n",
    "    ax[2][i].imshow(data_noise[i])\n",
    "\n",
    "for i in range(nCol):\n",
    "    ax[3][i].set_title('y_0')\n",
    "    ax[3][i].imshow(pred[i])\n",
    "\n",
    "for i in range(nCol):\n",
    "    ax[4][i].set_title('y_n')\n",
    "    ax[4][i].imshow(pred_update[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(file_figure, bbox_inches='tight', dpi=300)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/nas/users/minhyeok/energy_based_model/model/MNIST/2023_03_31/16_54_28.pth'\n",
    "ckpt = torch.load(path)\n",
    "device = torch.device(f'cuda:{args.device_cuda}' if torch.cuda.is_available() else 'mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = models.energy(\n",
    "            dim_channel=args.data_channel,\n",
    "            dim_feature=args.model_dim_feature,\n",
    "            dim_latent=args.model_dim_latent,\n",
    "            model_conv=args.model_conv,\n",
    "            activation=args.model_activation,\n",
    "            activation_output='identity',\n",
    "            use_batch_norm=args.model_use_batch_norm,\n",
    "            use_skip=False,\n",
    "            use_dual_input=False).to(device)\n",
    "\n",
    "model = models.auto_encoder(\n",
    "            dim_channel=args.data_channel,\n",
    "            dim_feature=args.model_dim_feature,\n",
    "            dim_latent=args.model_dim_latent,\n",
    "            model_conv=args.model_conv, \n",
    "            activation=args.model_activation, \n",
    "            activation_output=args.model_output, \n",
    "            use_batch_norm=args.model_use_batch_norm, \n",
    "            use_skip=args.model_use_skip,   # skip connection 사용 유무\n",
    "            use_dual_input=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(ckpt['state_dict_model'])\n",
    "model.eval()\n",
    "for j, (image, _) in enumerate(dataloader_test):\n",
    "    image = image.to(device)\n",
    "    pred, latent = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_update = Parameter(pred, requires_grad=True) \n",
    "\n",
    "for k in range(args.optim_length_langevin): \n",
    "    energy_negative = energy(pred_update)\n",
    "    loss_negative   = losses.compute_loss_negative(energy_negative)\n",
    "    loss_negative.backward()\n",
    "    noise = torch.randn_like(pred_update.data)    # N(mean=0, std=1)\n",
    "    pred_update.data = pred_update.data - args.optim_lr_data * pred_update.grad + args.optim_lr_langevin * noise\n",
    "    \n",
    "    pred_update.grad.detach_()\n",
    "    pred_update.grad.zero_()\n",
    "    plt.imshow(pred_update[0,0,...].detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-3.4417e-05, -6.8401e-04,  1.0386e-03,  ..., -3.4018e-04,\n",
       "           -1.3260e-04,  1.9383e-03],\n",
       "          [ 9.9610e-04,  7.4576e-04,  9.8004e-04,  ..., -1.9869e-04,\n",
       "           -2.2159e-04,  1.0002e+00],\n",
       "          [-7.9882e-05, -9.1370e-05, -8.4302e-04,  ...,  1.0557e-03,\n",
       "            1.0943e-04,  9.9900e-01],\n",
       "          ...,\n",
       "          [-6.3267e-04, -2.7354e-04,  4.3642e-04,  ..., -5.6366e-04,\n",
       "            4.3388e-04,  9.9870e-01],\n",
       "          [ 1.3541e-04,  1.0050e-03, -2.9598e-04,  ..., -7.0784e-04,\n",
       "           -6.1850e-04,  1.0005e+00],\n",
       "          [ 9.9999e-01,  1.0005e+00,  1.0004e+00,  ...,  9.9988e-01,\n",
       "            9.9997e-01,  9.9944e-01]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3035e755443aca2cb3217176319455f49be3dbda138992f9ddc44b43d021598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
