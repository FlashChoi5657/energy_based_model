{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from torch.nn.parameter import Parameter\n",
        "from torchmetrics import PeakSignalNoiseRatio\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import datetime, random\n",
        "import csv\n",
        "import os\n",
        "import argparse\n",
        "from models import CondEnergyModel, UNet\n",
        "from utils import permute, to_numpy, init_weights, Self_Energy_log, get_dataloaders\n",
        "from utils import gaussian_noise, sp_noise, delete_square, generate_Y0\n",
        "\n",
        "# ======================================================================\n",
        "# Input arguments\n",
        "# ======================================================================\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--name\", type=str, default='MNIST')\n",
        "parser.add_argument(\"--dataset\", type=str, default=\"MNIST\")\n",
        "parser.add_argument(\"--train_size\", type=int, default=60000)\n",
        "parser.add_argument(\"--test_size\", type=int, default=10000)\n",
        "\n",
        "parser.add_argument(\"--in_channel\", type=int, default=1)\n",
        "parser.add_argument(\"--img_size\", type=int, default=32)\n",
        "parser.add_argument(\"--dim_feature\", type=int, default=32)\n",
        "\n",
        "parser.add_argument(\"--gaussian_noise\", type=float, default=0.15)\n",
        "parser.add_argument(\"--sp_noise\", type=float, default=0.1)\n",
        "parser.add_argument(\"--square_pixels\", type=int, default=20)\n",
        "parser.add_argument(\"--degradation\", type=str, default='gaussian_noise')\n",
        "parser.add_argument(\"--Y0_type\", type=str, default='random')\n",
        "\n",
        "parser.add_argument(\"--lr_energy_model\", type=float, default=0.0001)\n",
        "parser.add_argument(\"--lr_langevin_min\", type=float, default=0.01)\n",
        "parser.add_argument(\"--lr_langevin_max\", type=float, default=0.1)\n",
        "parser.add_argument(\"--number_step_langevin\", type=int, default=50)\n",
        "\n",
        "parser.add_argument(\"--use_energy_sched\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--use_subset\", action=\"store_true\", default=True)\n",
        "parser.add_argument(\"--use_label\", type=int, default=5)\n",
        "\n",
        "parser.add_argument(\"--epochs\", type=int, default=100)\n",
        "parser.add_argument(\"--save_plot\", type=int, default=20)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=100)\n",
        "\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "\n",
        "parser.add_argument(\"--train_ratio\", type=float, default=1.0)\n",
        "parser.add_argument(\"--use_unpaired\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--regular_data\", type=float, default=0.0)\n",
        "parser.add_argument(\"--init_noise_decay\", type=float, default=1.0)\n",
        "# parser.add_argument(\"--use_gp\", action=\"store_true\", default=True)\n",
        "# parser.add_argument(\"--use_energy_reg\", action=\"store_true\", default=False)\n",
        "parser.add_argument(\"--energy_reg_weight\", type=float, default=0.0005)\n",
        "# parser.add_argument(\"--use_energy_L2_reg\", action=\"store_true\", default=True)\n",
        "parser.add_argument(\"--energy_L2_reg_weight\", type=float, default=0.0)\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# ======================================================================\n",
        "# Options\n",
        "# ======================================================================\n",
        "# curr_dir_path         = os.path.join(os.path.dirname(os.path.abspath('')), '..', 'experiments')\n",
        "curr_dir_path         = '/nas/users/minhyeok/energy_based_model/code/experiments'\n",
        "name                  = args.name\n",
        "dir_work              = os.path.join(curr_dir_path, name)\n",
        "cuda_device           = 0\n",
        "NGPU                  = torch.cuda.device_count()\n",
        "device                = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
        "# device                = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'\n",
        "batch_size            = args.batch_size\n",
        "number_epoch          = args.epochs\n",
        "use_energy_sched      = args.use_energy_sched\n",
        "sched_step_size       = 10\n",
        "sched_gamma           = 0.93\n",
        "lr_energy_model       = args.lr_energy_model\n",
        "lr_langevin_max       = args.lr_langevin_max\n",
        "lr_langevin_min       = args.lr_langevin_min\n",
        "number_step_langevin  = args.number_step_langevin\n",
        "regular_data          = args.regular_data\n",
        "init_noise_decay      = args.init_noise_decay\n",
        "# use_reg               = args.use_energy_reg\n",
        "reg_weight            = args.energy_reg_weight\n",
        "# use_L2_reg            = args.use_energy_L2_reg\n",
        "L2_reg_weight         = args.energy_L2_reg_weight\n",
        "add_noise             = True\n",
        "use_unpaired          = args.use_unpaired\n",
        "in_channel            = args.in_channel\n",
        "dim_feature           = args.dim_feature\n",
        "dim_output            = 1\n",
        "degradation           = args.degradation\n",
        "Y0_type               = args.Y0_type\n",
        "sigma_noise           = args.gaussian_noise\n",
        "snp_noise             = args.sp_noise\n",
        "square_pixels         = args.square_pixels\n",
        "seed                  = 0\n",
        "list_lr_langevin      = np.linspace(lr_langevin_max, lr_langevin_min, num=number_epoch, endpoint=True)\n",
        "pl.seed_everything(0)\n",
        "\n",
        "# ======================================================================\n",
        "# Dataset \n",
        "# ======================================================================\n",
        "# dir_data    = os.path.join(dir_work, 'data')\n",
        "dir_data = '/hdd1/dataset'\n",
        "dir_dataset = args.dataset\n",
        "im_size     = args.img_size\n",
        "scale_range = [-1, 1]\n",
        "train_size  = args.train_size\n",
        "test_size   = args.test_size\n",
        "use_subset  = args.use_subset\n",
        "use_label   = args.use_label\n",
        "train_ratio = args.train_ratio\n",
        "\n",
        "# ======================================================================\n",
        "# Path for the results\n",
        "# ======================================================================\n",
        "dir_figure = os.path.join(dir_work, 'figure')\n",
        "dir_option = os.path.join(dir_work, 'option')\n",
        "dir_result = os.path.join(dir_work, 'result')\n",
        "dir_model  = os.path.join(dir_work, 'model')\n",
        "now        = datetime.datetime.now()\n",
        "date_stamp = now.strftime('%Y_%m_%d')\n",
        "time_stamp = now.strftime('%H_%M_%S')\n",
        "\n",
        "path_figure = os.path.join(dir_figure, dir_dataset)\n",
        "path_option = os.path.join(dir_option, dir_dataset)\n",
        "path_result = os.path.join(dir_result, dir_dataset)\n",
        "path_model  = os.path.join(dir_model, dir_dataset)\n",
        "\n",
        "date_figure = os.path.join(path_figure, date_stamp)\n",
        "date_option = os.path.join(path_option, date_stamp)\n",
        "date_result = os.path.join(path_result, date_stamp)\n",
        "date_model  = os.path.join(path_model, date_stamp)\n",
        "\n",
        "file_figure       = os.path.join(date_figure, f'{time_stamp}.png')\n",
        "file_option       = os.path.join(date_option, f'{time_stamp}.ini')\n",
        "file_result       = os.path.join(date_result, f'{time_stamp}.csv')\n",
        "self_file_model   = os.path.join(date_model, f'self.{time_stamp}.pth')\n",
        "energy_file_model = os.path.join(date_model, f'energy.{time_stamp}.pth')\n",
        "  \n",
        "if not os.path.exists(dir_figure):  os.makedirs(dir_figure)\n",
        "\n",
        "if not os.path.exists(dir_option):  os.makedirs(dir_option)\n",
        "\n",
        "if not os.path.exists(dir_result):  os.makedirs(dir_result)\n",
        "\n",
        "if not os.path.exists(dir_model):  os.makedirs(dir_model)\n",
        "\n",
        "if not os.path.exists(path_figure):  os.makedirs(path_figure)\n",
        "\n",
        "if not os.path.exists(path_option):  os.makedirs(path_option)\n",
        "\n",
        "if not os.path.exists(path_result):  os.makedirs(path_result)\n",
        "\n",
        "if not os.path.exists(path_model):  os.makedirs(path_model)\n",
        "\n",
        "if not os.path.exists(date_figure):  os.makedirs(date_figure)\n",
        "\n",
        "if not os.path.exists(date_option):  os.makedirs(date_option)\n",
        "\n",
        "if not os.path.exists(date_result):  os.makedirs(date_result)\n",
        "\n",
        "if not os.path.exists(date_model):  os.makedirs(date_model)\n",
        "\n",
        "# ======================================================================\n",
        "# Dataloaders \n",
        "# ======================================================================\n",
        "dataloader_train, dataloader_test, _, vis_im_transform = get_dataloaders(dir_data, dir_dataset, im_size, \n",
        "                                                                         in_channel, batch_size, train_size, \n",
        "                                                                         train_ratio, test_size, \n",
        "                                                                         use_subset, use_label, \n",
        "                                                                         scale_range, use_unpaired)\n",
        "\n",
        "# ======================================================================\n",
        "# Apply degradation\n",
        "# ======================================================================\n",
        "if degradation == 'gaussian_noise':\n",
        "  degradation_func = lambda im: gaussian_noise(im, sigma_noise) # original + noise\n",
        "\n",
        "elif degradation == 'sp_noise':\n",
        "  degradation_func = lambda im: sp_noise(im, snp_noise)\n",
        "\n",
        "elif degradation == 'delete_square':\n",
        "  degradation_func = lambda im: delete_square(im, square_pixels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 64, 64]           3,456\n",
            "       BatchNorm2d-2          [-1, 128, 64, 64]             256\n",
            "              ReLU-3          [-1, 128, 64, 64]               0\n",
            "            Conv2d-4          [-1, 128, 64, 64]         147,456\n",
            "       BatchNorm2d-5          [-1, 128, 64, 64]             256\n",
            "              ReLU-6          [-1, 128, 64, 64]               0\n",
            "        DoubleConv-7          [-1, 128, 64, 64]               0\n",
            "         MaxPool2d-8          [-1, 128, 32, 32]               0\n",
            "            Conv2d-9          [-1, 256, 32, 32]         294,912\n",
            "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
            "             ReLU-11          [-1, 256, 32, 32]               0\n",
            "           Conv2d-12          [-1, 256, 32, 32]         589,824\n",
            "      BatchNorm2d-13          [-1, 256, 32, 32]             512\n",
            "             ReLU-14          [-1, 256, 32, 32]               0\n",
            "       DoubleConv-15          [-1, 256, 32, 32]               0\n",
            "             Down-16          [-1, 256, 32, 32]               0\n",
            "        MaxPool2d-17          [-1, 256, 16, 16]               0\n",
            "           Conv2d-18          [-1, 512, 16, 16]       1,179,648\n",
            "      BatchNorm2d-19          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-20          [-1, 512, 16, 16]               0\n",
            "           Conv2d-21          [-1, 512, 16, 16]       2,359,296\n",
            "      BatchNorm2d-22          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-23          [-1, 512, 16, 16]               0\n",
            "       DoubleConv-24          [-1, 512, 16, 16]               0\n",
            "             Down-25          [-1, 512, 16, 16]               0\n",
            "        MaxPool2d-26            [-1, 512, 8, 8]               0\n",
            "           Conv2d-27           [-1, 1024, 8, 8]       4,718,592\n",
            "      BatchNorm2d-28           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-29           [-1, 1024, 8, 8]               0\n",
            "           Conv2d-30           [-1, 1024, 8, 8]       9,437,184\n",
            "      BatchNorm2d-31           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-32           [-1, 1024, 8, 8]               0\n",
            "       DoubleConv-33           [-1, 1024, 8, 8]               0\n",
            "             Down-34           [-1, 1024, 8, 8]               0\n",
            "  ConvTranspose2d-35          [-1, 512, 16, 16]       2,097,664\n",
            "           Conv2d-36          [-1, 512, 16, 16]       4,718,592\n",
            "      BatchNorm2d-37          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-38          [-1, 512, 16, 16]               0\n",
            "           Conv2d-39          [-1, 512, 16, 16]       2,359,296\n",
            "      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-41          [-1, 512, 16, 16]               0\n",
            "       DoubleConv-42          [-1, 512, 16, 16]               0\n",
            "               Up-43          [-1, 512, 16, 16]               0\n",
            "  ConvTranspose2d-44          [-1, 256, 32, 32]         524,544\n",
            "           Conv2d-45          [-1, 256, 32, 32]       1,179,648\n",
            "      BatchNorm2d-46          [-1, 256, 32, 32]             512\n",
            "             ReLU-47          [-1, 256, 32, 32]               0\n",
            "           Conv2d-48          [-1, 256, 32, 32]         589,824\n",
            "      BatchNorm2d-49          [-1, 256, 32, 32]             512\n",
            "             ReLU-50          [-1, 256, 32, 32]               0\n",
            "       DoubleConv-51          [-1, 256, 32, 32]               0\n",
            "               Up-52          [-1, 256, 32, 32]               0\n",
            "  ConvTranspose2d-53          [-1, 128, 64, 64]         131,200\n",
            "           Conv2d-54          [-1, 128, 64, 64]         294,912\n",
            "      BatchNorm2d-55          [-1, 128, 64, 64]             256\n",
            "             ReLU-56          [-1, 128, 64, 64]               0\n",
            "           Conv2d-57          [-1, 128, 64, 64]         147,456\n",
            "      BatchNorm2d-58          [-1, 128, 64, 64]             256\n",
            "             ReLU-59          [-1, 128, 64, 64]               0\n",
            "       DoubleConv-60          [-1, 128, 64, 64]               0\n",
            "               Up-61          [-1, 128, 64, 64]               0\n",
            "           Conv2d-62            [-1, 3, 64, 64]             387\n",
            "          OutConv-63            [-1, 3, 64, 64]               0\n",
            "             Tanh-64            [-1, 3, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 30,785,155\n",
            "Trainable params: 30,785,155\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 121.03\n",
            "Params size (MB): 117.44\n",
            "Estimated Total Size (MB): 238.51\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import torchsummary as sum\n",
        "unet = UNet(3, 64, 3).cuda()\n",
        "print(sum.summary(unet, (3, 64, 64)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/minhyeok/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ======================================================================\n",
        "# Evaluation\n",
        "# ======================================================================\n",
        "PSNR = PeakSignalNoiseRatio().to(device)\n",
        "\n",
        "# ======================================================================\n",
        "# Instantiations\n",
        "# ======================================================================\n",
        "energy = CondEnergyModel(in_channel * 2, dim_feature, dim_output, \n",
        "                          activation='silu',\n",
        "                          scale_range=scale_range,\n",
        "                          use_reg=False, \n",
        "                          reg_weight=reg_weight,\n",
        "                          use_gp=True, \n",
        "                          use_L2_reg=False,\n",
        "                          L2_reg_weight=L2_reg_weight)\n",
        "if NGPU > 1:\n",
        "    # from torch.nn.parallel import DistributedDataParallel as ddp\n",
        "    energy = torch.nn.DataParallel(energy, device_ids=list(range(NGPU)))\n",
        "    energy = energy.module.cuda()\n",
        "else:\n",
        "    energy = energy.to(device)\n",
        "# ======================================================================\n",
        "# Weights initializations\n",
        "# ======================================================================\n",
        "# TODO: implement weights initialization method\n",
        "\n",
        "# ======================================================================\n",
        "# Optimizers\n",
        "# ======================================================================\n",
        "optim_energy = torch.optim.Adam(energy.parameters(), lr=lr_energy_model, betas=(args.b1, 0.999))\n",
        "\n",
        "# ======================================================================\n",
        "# Schedulers\n",
        "# ======================================================================\n",
        "# ExponentialLR\n",
        "sched_optim_energy = torch.optim.lr_scheduler.StepLR(optim_energy, step_size=sched_step_size, gamma=sched_gamma)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "\n",
        "    def __init__(self, model, img_shape, sample_size=args.batch_size, max_len=8192):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            model - Neural network to use for modeling E_theta\n",
        "            img_shape - Shape of the images to model\n",
        "            sample_size - Batch size of the samples\n",
        "            max_len - Maximum number of data points to keep in the buffer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.img_shape = img_shape\n",
        "        self.sample_size = sample_size\n",
        "        self.max_len = max_len\n",
        "        self.examples = [(torch.rand((1,)+img_shape)*2-1) for _ in range(self.sample_size)]\n",
        "\n",
        "    def sample_new_exmps(self, steps=args.number_step_langevin, step_size=10):\n",
        "        \"\"\"\n",
        "        Function for getting a new batch of \"fake\" images.\n",
        "        Inputs:\n",
        "            steps - Number of iterations in the MCMC algorithm\n",
        "            step_size - Learning rate nu in the algorithm above\n",
        "        \"\"\"\n",
        "        # Choose 95% of the batch from the buffer, 5% generate from scratch\n",
        "        n_new = np.random.binomial(self.sample_size, 0.05)\n",
        "        rand_imgs = torch.rand((n_new,) + self.img_shape) * 2 - 1\n",
        "        old_imgs = torch.cat(random.choices(self.examples, k=self.sample_size-n_new), dim=0)\n",
        "        inp_imgs = torch.cat([rand_imgs, old_imgs], dim=0).detach().to(device)\n",
        "\n",
        "        # Perform MCMC sampling\n",
        "        inp_imgs = Sampler.generate_samples(self.model, inp_imgs, steps=steps, step_size=step_size)\n",
        "\n",
        "        # Add new images to the buffer and remove old ones if needed\n",
        "        self.examples = list(inp_imgs.to(torch.device(\"cpu\")).chunk(self.sample_size, dim=0)) + self.examples\n",
        "        self.examples = self.examples[:self.max_len]\n",
        "        return inp_imgs\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_samples(model, inp_imgs, steps=args.number_step_langevin, step_size=10, return_img_per_step=False):\n",
        "        \"\"\"\n",
        "        Function for sampling images for a given model.\n",
        "        Inputs:\n",
        "            model - Neural network to use for modeling E_theta\n",
        "            inp_imgs - Images to start from for sampling. If you want to generate new images, enter noise between -1 and 1.\n",
        "            steps - Number of iterations in the MCMC algorithm.\n",
        "            step_size - Learning rate nu in the algorithm above\n",
        "            return_img_per_step - If True, we return the sample at every iteration of the MCMC\n",
        "        \"\"\"\n",
        "        # Before MCMC: set model parameters to \"required_grad=False\"\n",
        "        # because we are only interested in the gradients of the input.\n",
        "        is_training = model.training\n",
        "        model.eval()\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "        inp_imgs.requires_grad = True\n",
        "\n",
        "        # Enable gradient calculation if not already the case\n",
        "        had_gradients_enabled = torch.is_grad_enabled()\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        # We use a buffer tensor in which we generate noise each loop iteration.\n",
        "        # More efficient than creating a new tensor every iteration.\n",
        "        noise = torch.randn(inp_imgs.shape, device=inp_imgs.device)\n",
        "\n",
        "        # List for storing generations at each step (for later analysis)\n",
        "        imgs_per_step = []\n",
        "\n",
        "        # Loop over K (steps)\n",
        "        for _ in range(steps):\n",
        "            # Part 1: Add noise to the input.\n",
        "            noise.normal_(0, 0.005)\n",
        "            inp_imgs.data.add_(noise.data)\n",
        "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
        "\n",
        "            # Part 2: calculate gradients for the current input.\n",
        "            out_imgs = -model(inp_imgs)\n",
        "            out_imgs.sum().backward()\n",
        "            inp_imgs.grad.data.clamp_(-0.03, 0.03) # For stabilizing and preventing too high gradients\n",
        "\n",
        "            # Apply gradients to our current samples\n",
        "            inp_imgs.data.add_(-step_size * inp_imgs.grad.data)\n",
        "            inp_imgs.grad.detach_()\n",
        "            inp_imgs.grad.zero_()\n",
        "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
        "\n",
        "            if return_img_per_step:\n",
        "                imgs_per_step.append(inp_imgs.clone().detach())\n",
        "\n",
        "        # Reactivate gradients for parameters for training\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "        model.train(is_training)\n",
        "\n",
        "        # Reset gradient calculation to setting before this function\n",
        "        torch.set_grad_enabled(had_gradients_enabled)\n",
        "\n",
        "        if return_img_per_step:\n",
        "            return torch.stack(imgs_per_step, dim=0)\n",
        "        else:\n",
        "            return inp_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 16, 16]             576\n",
            "       BatchNorm2d-2           [-1, 32, 16, 16]              64\n",
            "        Conv_Layer-3           [-1, 32, 16, 16]               0\n",
            "             Swish-4           [-1, 32, 16, 16]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          18,432\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "        Conv_Layer-7             [-1, 64, 8, 8]               0\n",
            "             Swish-8             [-1, 64, 8, 8]               0\n",
            "            Conv2d-9            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-10            [-1, 128, 4, 4]             256\n",
            "       Conv_Layer-11            [-1, 128, 4, 4]               0\n",
            "            Swish-12            [-1, 128, 4, 4]               0\n",
            "           Conv2d-13            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-14            [-1, 256, 2, 2]             512\n",
            "       Conv_Layer-15            [-1, 256, 2, 2]               0\n",
            "            Swish-16            [-1, 256, 2, 2]               0\n",
            "          Flatten-17                 [-1, 1024]               0\n",
            "           Linear-18                  [-1, 256]         262,400\n",
            "            Swish-19                  [-1, 256]               0\n",
            "           Linear-20                    [-1, 1]             257\n",
            "================================================================\n",
            "Total params: 651,265\n",
            "Trainable params: 651,265\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 4.00\n",
            "Forward/backward pass size (MB): 0.48\n",
            "Params size (MB): 2.48\n",
            "Estimated Total Size (MB): 6.96\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import torchsummary\n",
        "\n",
        "print(torchsummary.summary(energy, [(1,32,32),(1,32,32)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST:\n",
            " [   0/ 100]  [L_ebm=-3077.2586 | LR_ebm=0.00010 | PSNR_Y0=1.0700 | PSNR_Y:50=1.06999]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_8490/3221142983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     prediction_update = energy.update_prediction_langevin(image_noise, \n\u001b[0m\u001b[1;32m     48\u001b[0m                                                         \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                                         \u001b[0mnumber_step_langevin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/nas/users/minhyeok/energy_based_model/code/models.py\u001b[0m in \u001b[0;36mupdate_prediction_langevin\u001b[0;34m(self, x, prediction, number_step_langevin, lr_langevin, regular_data, add_noise, noise_decay, z_negative)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_step_langevin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/nas/users/minhyeok/energy_based_model/code/models.py\u001b[0m in \u001b[0;36mcompute_loss_inference\u001b[0;34m(self, negative_input, negative_output, z_negative)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CondEnergyModel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_negative\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_negative\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/nas/users/minhyeok/energy_based_model/code/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, a, b, z)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/nas/users/minhyeok/energy_based_model/code/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSwish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Swish'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCondEnergyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# Variables for the results \n",
        "# ======================================================================\n",
        "\n",
        "val_loss_energy_model_mean = np.zeros(number_epoch)\n",
        "val_loss_energy_model_std  = np.zeros(number_epoch)\n",
        "val_psnr_mean              = np.zeros(number_epoch)\n",
        "val_psnr_std               = np.zeros(number_epoch)\n",
        "val_psnr_langevin_mean     = np.zeros(number_epoch)\n",
        "val_psnr_langevin_std      = np.zeros(number_epoch)\n",
        "\n",
        "# ======================================================================\n",
        "# Training\n",
        "# ======================================================================\n",
        "\n",
        "for i in range(number_epoch):\n",
        "  val_loss_energy_model = list()\n",
        "  val_psnr              = list()\n",
        "  val_psnr_langevin     = list()\n",
        "\n",
        "  for j, (image, _) in enumerate(iter(dataloader_train)):\n",
        "    energy = energy.train()\n",
        "    # -------------------------------------------------------------------\n",
        "    # Applied degradation\n",
        "    # -------------------------------------------------------------------\n",
        "    if use_unpaired:\n",
        "      image, image2 = torch.split(image, batch_size)\n",
        "      image2_noise  = degradation_func(image2)\n",
        "      image2        = image2.to(device)\n",
        "      image2_noise  = image2_noise.to(device)\n",
        "\n",
        "    else:\n",
        "      image_noise = degradation_func(image)\n",
        "\n",
        "    image       = image.to(device)\n",
        "    image_noise = image_noise.to(device)\n",
        "\n",
        "    # -------------------------------------------------------------------\n",
        "    # Y0 generation identity, gaussian distribution, zero\n",
        "    # -------------------------------------------------------------------\n",
        "    prediction = generate_Y0(image_noise, Y0_type)\n",
        "\n",
        "    # -------------------------------------------------------------------\n",
        "    # Yn generation\n",
        "    # -------------------------------------------------------------------\n",
        "    \n",
        "    prediction_update = energy.update_prediction_langevin(image_noise, \n",
        "                                                        prediction.detach(), \n",
        "                                                        number_step_langevin,  \n",
        "                                                        list_lr_langevin[i], \n",
        "                                                        regular_data, \n",
        "                                                        add_noise, \n",
        "                                                        init_noise_decay)\n",
        "    \n",
        "    # prediction_update = energy.sample_langevin(image_noise, energy,number_step_langevin,\n",
        "    #                                            list_lr_langevin[i],\n",
        "    #                                            add_noise=True)\n",
        "    energy.train()\n",
        "    # -------------------------------------------------------------------\n",
        "    # EBM gradient evaluation\n",
        "    # -------------------------------------------------------------------\n",
        "    optim_energy.zero_grad()\n",
        "    if use_unpaired:\n",
        "      loss_energy = energy.compute_loss(image2_noise, image2, image_noise, prediction_update.detach())\n",
        "\n",
        "    else:\n",
        "      loss_energy = energy.compute_loss(image_noise, image, prediction, prediction_update.detach())\n",
        "      loss_energy.backward()\n",
        "\n",
        "    value_psnr          = to_numpy(PSNR(prediction, image))\n",
        "    value_psnr_langevin = to_numpy(PSNR(prediction_update, image))\n",
        "\n",
        "    prediction = prediction_update\n",
        "    # -------------------------------------------------------------------\n",
        "    # Update networks\n",
        "    # -------------------------------------------------------------------\n",
        "    optim_energy.step()\n",
        "\n",
        "    # -------------------------------------------------------------------\n",
        "    # Save results for each batch iteration\n",
        "    # -------------------------------------------------------------------        \n",
        "    val_loss_energy_model.append(loss_energy.item())\n",
        "    val_psnr.append(value_psnr)\n",
        "    val_psnr_langevin.append(value_psnr_langevin)\n",
        "      \n",
        "  # -------------------------------------------------------------------\n",
        "  # Update schedulers\n",
        "  # -------------------------------------------------------------------\n",
        "  lr_energy_model = sched_optim_energy.get_last_lr()[0]\n",
        "\n",
        "  if use_energy_sched:\n",
        "    sched_optim_energy.step()\n",
        "\n",
        "  # -------------------------------------------------------------------\n",
        "  # Save results for each epoch\n",
        "  # -------------------------------------------------------------------\n",
        "  val_loss_energy_model_mean[i] = np.mean(val_loss_energy_model)\n",
        "  val_loss_energy_model_std[i]  = np.std(val_loss_energy_model)\n",
        "  val_psnr_mean[i]              = np.mean(val_psnr)\n",
        "  val_psnr_std[i]               = np.std(val_psnr)\n",
        "  val_psnr_langevin_mean[i]     = np.mean(val_psnr_langevin)\n",
        "  val_psnr_langevin_std[i]      = np.std(val_psnr_langevin)\n",
        "\n",
        "  log = Self_Energy_log(number_step_langevin) % (i, \n",
        "                                                  number_epoch, \n",
        "                                                  val_loss_energy_model_mean[i], \n",
        "                                                  lr_energy_model, \n",
        "                                                  val_psnr_mean[i], \n",
        "                                                  val_psnr_langevin_mean[i])\n",
        "  print(f\"{name}:\\n\", log)\n",
        "  if i % args.save_plot == 0 and i != 0:\n",
        "    energy.eval()\n",
        "    fig, ax = plt.subplots(4, 10, figsize = (3 * 15, 3 * 10))\n",
        "    for k in range(10):\n",
        "      rand = random.randrange(len(dataloader_train))\n",
        "      ax[0][k].set_title('Train (Input)')\n",
        "      ax[0][k].imshow((tr(vis_im_transform((image[k,...]).detach().cpu().numpy()))* 255).astype(np.uint8))\n",
        "      ax[1][k].set_title('Train (Dataset)')\n",
        "      ax[1][k].imshow((tr(vis_im_transform((image_noise[k,...]).detach().cpu().numpy()))*255).astype(np.uint8))\n",
        "      ax[2][k].set_title('Train (ID)')\n",
        "      ax[2][k].imshow((tr(vis_im_transform((prediction[k,...]).detach().cpu().numpy()))*255).astype(np.uint8))\n",
        "      ax[3][k].set_title('Train (Langevin)')\n",
        "      ax[3][k].imshow((tr(vis_im_transform((prediction_update[k,...]).detach().cpu().numpy()))*255).astype(np.uint8))\n",
        "    time_ = datetime.datetime.now().strftime('%H_%M')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(f'{date_figure}/log_step_{i}_{time_}.png', bbox_inches='tight', dpi=300)\n",
        "    plt.close(fig)\n",
        "  # TODO: find a condition to break the loop\n",
        "  # if np.isnan(val_psnr_mean[i]) or ((i > 10) and (val_psnr_mean[i] < 5)) or ((i > 100) and (val_psnr_mean[i] < 10)):\n",
        "  #   print(f'Terminating the run after {i} epochs..')\n",
        "  #   break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# Model evaluation for inferences\n",
        "# ======================================================================\n",
        "energy = energy.eval()\n",
        "\n",
        "# ======================================================================\n",
        "# Training results\n",
        "# ======================================================================\n",
        "(image_train, _) = next(iter(dataloader_train))\n",
        "image_noise_train = degradation_func(image_train)\n",
        "image_train       = image_train.to(device)\n",
        "image_noise_train = image_noise_train.to(device)\n",
        "y_train           = generate_Y0(image_noise_train, Y0_type)\n",
        "y_update_train    = energy.update_prediction_langevin(image_noise_train, \n",
        "                                                      y_train.detach(), \n",
        "                                                      number_step_langevin, \n",
        "                                                      list_lr_langevin[-1], \n",
        "                                                      regular_data, \n",
        "                                                      add_noise, \n",
        "                                                      init_noise_decay)\n",
        "\n",
        "image_train       = to_numpy(permute(image_train)).squeeze()\n",
        "image_noise_train = to_numpy(permute(image_noise_train)).squeeze()\n",
        "y_train           = to_numpy(permute(y_train)).squeeze()\n",
        "y_update_train    = to_numpy(permute(y_update_train)).squeeze()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Training performance measuring\n",
        "# -------------------------------------------------------------------\n",
        "train_self_data_psnr     = np.zeros(len(dataloader_train))\n",
        "train_energy_data_psnr = np.zeros(len(dataloader_train))\n",
        "\n",
        "for i, (image_train_, _) in enumerate(iter(dataloader_train)):\n",
        "  image_noise_train_ = degradation_func(image_train_)\n",
        "  image_train_       = image_train_.to(device)\n",
        "  image_noise_train_ = image_noise_train_.to(device)\n",
        "  y_train_           = generate_Y0(image_noise_train_, Y0_type)\n",
        "  y_update_train_    = energy.update_prediction_langevin(image_noise_train_, \n",
        "                                                         y_train_.detach(), \n",
        "                                                         number_step_langevin, \n",
        "                                                         list_lr_langevin[-1], \n",
        "                                                         regular_data, \n",
        "                                                         add_noise, \n",
        "                                                         init_noise_decay)\n",
        "\n",
        "  train_self_data_psnr[i]     = to_numpy(PSNR(y_train_, image_train_)).mean()\n",
        "  train_energy_data_psnr[i] = to_numpy(PSNR(y_update_train_, image_train_)).mean()\n",
        "\n",
        "# ======================================================================\n",
        "# Testing results\n",
        "# ======================================================================\n",
        "(image_test, _) = next(iter(dataloader_test))\n",
        "image_noise_test = degradation_func(image_test)\n",
        "image_test       = image_test.to(device)\n",
        "image_noise_test = image_noise_test.to(device)\n",
        "y_test           = generate_Y0(image_noise_test, Y0_type)\n",
        "y_update_test    = energy.update_prediction_langevin(image_noise_test, \n",
        "                                                     y_test.detach(), \n",
        "                                                     number_step_langevin, \n",
        "                                                     list_lr_langevin[-1], \n",
        "                                                     regular_data, \n",
        "                                                     add_noise, \n",
        "                                                     init_noise_decay)\n",
        "\n",
        "image_test       = to_numpy(permute(image_test)).squeeze()\n",
        "image_noise_test = to_numpy(permute(image_noise_test)).squeeze()\n",
        "y_test           = to_numpy(permute(y_test)).squeeze()\n",
        "y_update_test    = to_numpy(permute(y_update_test)).squeeze()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Testing performance measuring\n",
        "# -------------------------------------------------------------------\n",
        "test_self_data_psnr     = np.zeros(len(dataloader_test))\n",
        "test_energy_data_psnr = np.zeros(len(dataloader_test))\n",
        "\n",
        "for i, (image_test_, _) in enumerate(iter(dataloader_test)):\n",
        "  image_noise_test_ = degradation_func(image_test_)\n",
        "  image_test_       = image_test_.to(device)\n",
        "  image_noise_test_ = image_noise_test_.to(device)\n",
        "  y_test_           = generate_Y0(image_noise_test_, Y0_type)\n",
        "  y_update_test_    = energy.update_prediction_langevin(image_noise_test_, \n",
        "                                                        y_test_.detach(), \n",
        "                                                        number_step_langevin, \n",
        "                                                        list_lr_langevin[-1], \n",
        "                                                        regular_data, \n",
        "                                                        add_noise, \n",
        "                                                        init_noise_decay)\n",
        "\n",
        "  test_self_data_psnr[i]     = to_numpy(PSNR(y_test_, image_test_)).mean()\n",
        "  test_energy_data_psnr[i] = to_numpy(PSNR(y_update_test_, image_test_)).mean()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Save models\n",
        "# -------------------------------------------------------------------\n",
        "torch.save(energy, energy_file_model)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Save the options\n",
        "# -------------------------------------------------------------------\n",
        "with open(file_option, 'w') as f:\n",
        "  f.write('{}: {}\\n'.format('work directory', dir_work))\n",
        "  f.write('{}: {}\\n'.format('cuda device', cuda_device))\n",
        "  f.write('{}: {}\\n'.format('seed', seed))\n",
        "  f.write('{}: {}\\n'.format('dataset', dir_dataset))\n",
        "  f.write('{}: {}\\n'.format('Y0 type', Y0_type))\n",
        "  f.write('{}: {}\\n'.format('image size', im_size))\n",
        "  f.write('{}: {}\\n'.format('scale range', scale_range))\n",
        "  f.write('{}: {}\\n'.format('train size', train_size))\n",
        "  f.write('{}: {}\\n'.format('test size', test_size))\n",
        "  f.write('{}: {}\\n'.format('use subset', use_subset))\n",
        "  f.write('{}: {}\\n'.format('use label', use_label))\n",
        "  f.write('{}: {}\\n'.format('batch size', batch_size))\n",
        "  f.write('{}: {}\\n'.format('number epoch', number_epoch))\n",
        "  f.write('{}: {}\\n'.format('use energy scheduler', use_energy_sched))\n",
        "  f.write('{}: {}\\n'.format('scheduler step size', sched_step_size))\n",
        "  f.write('{}: {}\\n'.format('scheduler gamma', sched_gamma))\n",
        "  f.write('{}: {}\\n'.format('lr energy model', lr_energy_model))\n",
        "  f.write('{}: {}\\n'.format('lr langevin max', lr_langevin_max))\n",
        "  f.write('{}: {}\\n'.format('lr langevin min', lr_langevin_min))\n",
        "  f.write('{}: {}\\n'.format('number step langevin', number_step_langevin))\n",
        "  f.write('{}: {}\\n'.format('regular data', regular_data))\n",
        "  f.write('{}: {}\\n'.format('langevin noise decay factor', init_noise_decay))\n",
        "  # f.write('{}: {}\\n'.format('use energy weights regularization', use_reg))\n",
        "  f.write('{}: {}\\n'.format('energy weights regularization weight', reg_weight))\n",
        "  # f.write('{}: {}\\n'.format('use energy L2 weights regularization', use_L2_reg))\n",
        "  f.write('{}: {}\\n'.format('energy L2 weights regularization weight', L2_reg_weight))\n",
        "  f.write('{}: {}\\n'.format('add noise', add_noise))\n",
        "  f.write('{}: {}\\n'.format('use unpaired', use_unpaired))\n",
        "  f.write('{}: {}\\n'.format('sigma noise', sigma_noise))\n",
        "  f.write('{}: {}\\n'.format('salt and pepper noise', snp_noise))\n",
        "  f.write('{}: {}\\n'.format('delete square pixels', square_pixels))\n",
        "  f.write('{}: {}\\n'.format('degradation', degradation))\n",
        "  f.write('{}: {}\\n'.format('in channel', in_channel))\n",
        "  f.write('{}: {}\\n'.format('dim feature', dim_feature))\n",
        "  f.write('{}: {}\\n'.format('dim output', dim_output))\n",
        "  f.write('{}: {}\\n'.format('train id psnr mean', np.mean(train_self_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('train id psnr std', np.std(train_self_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('train energy psnr mean', np.mean(train_energy_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('train energy psnr std', np.std(train_energy_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('test id psnr mean', np.mean(test_self_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('test id psnr std', np.std(test_self_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('test energy psnr mean', np.mean(test_energy_data_psnr)))\n",
        "  f.write('{}: {}\\n'.format('test energy psnr std', np.std(test_energy_data_psnr)))\n",
        "\n",
        "f.close()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Save the results\n",
        "# -------------------------------------------------------------------   \n",
        "with open(file_result, 'w', newline='') as f:\n",
        "  writer = csv.writer(f, delimiter=',')\n",
        "  writer.writerow(val_loss_energy_model_mean)\n",
        "  writer.writerow(val_loss_energy_model_std)\n",
        "  writer.writerow(val_psnr_mean)\n",
        "  writer.writerow(val_psnr_std)\n",
        "  writer.writerow(val_psnr_langevin_mean)\n",
        "  writer.writerow(val_psnr_langevin_std)\n",
        "  writer.writerow(train_self_data_psnr)\n",
        "  writer.writerow(train_energy_data_psnr)\n",
        "  writer.writerow(test_self_data_psnr)\n",
        "  writer.writerow(test_energy_data_psnr)\n",
        "\n",
        "f.close()\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Save the figures from training\n",
        "# -------------------------------------------------------------------\n",
        "nRow  = 9\n",
        "nCol  = 5\n",
        "fSize = 3\n",
        "\n",
        "fig, ax = plt.subplots(nRow, nCol, figsize=(fSize * nCol, fSize * nRow))\n",
        "\n",
        "ax[0][0].set_title('Energy Model')\n",
        "ax[0][0].plot(val_loss_energy_model_mean, color='red', label='Loss')\n",
        "ax[0][0].legend()\n",
        "\n",
        "ax[0][1].set_title('Train PSNR')\n",
        "ax[0][1].plot(val_psnr_mean, color='red', label='ID')\n",
        "ax[0][1].plot(val_psnr_langevin_mean, color='green', label='Langevin')\n",
        "ax[0][1].legend()\n",
        "\n",
        "bplot_colors = ['pink', 'lightgreen']\n",
        "\n",
        "ax[0][2].set_title('ID Data PSNR')\n",
        "ax[0][2].yaxis.grid(True)\n",
        "bplot0 = ax[0][2].boxplot([train_self_data_psnr, \n",
        "                           test_self_data_psnr], 0, vert=True, patch_artist=True, labels=['Train', 'Test'])\n",
        "for patch, color in zip(bplot0['boxes'], bplot_colors):\n",
        "  patch.set_facecolor(color)\n",
        "\n",
        "ax[0][3].set_title('Energy Data PSNR')\n",
        "ax[0][3].yaxis.grid(True)\n",
        "bplot1 = ax[0][3].boxplot([train_energy_data_psnr, \n",
        "                           test_energy_data_psnr], 0, vert=True, patch_artist=True, labels=['Train', 'Test'])\n",
        "for patch, color in zip(bplot1['boxes'], bplot_colors):\n",
        "  patch.set_facecolor(color)\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[1][i].set_title('Train (Input)')\n",
        "  if in_channel == 1:\n",
        "    ax[1][i].imshow(vis_im_transform(image_noise_train[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[1][i].imshow(vis_im_transform(image_noise_train[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[2][i].set_title('Train (Dataset)')\n",
        "  if in_channel == 1:\n",
        "    ax[2][i].imshow(vis_im_transform(image_train[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[2][i].imshow(vis_im_transform(image_train[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[3][i].set_title('Train (ID)')\n",
        "  if in_channel == 1:\n",
        "    ax[3][i].imshow(vis_im_transform(y_train[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[3][i].imshow(vis_im_transform(y_train[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[4][i].set_title('Train (Langevin)')\n",
        "  if in_channel == 1:\n",
        "    ax[4][i].imshow(vis_im_transform(y_update_train[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[4][i].imshow(vis_im_transform(y_update_train[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[5][i].set_title('Test (Input)')\n",
        "  if in_channel == 1:\n",
        "    ax[5][i].imshow(vis_im_transform(image_noise_test[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[5][i].imshow(vis_im_transform(image_noise_test[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[6][i].set_title('Test (Dataset)')\n",
        "  if in_channel == 1:\n",
        "    ax[6][i].imshow(vis_im_transform(image_test[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[6][i].imshow(vis_im_transform(image_test[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[7][i].set_title('Test (ID)')\n",
        "  if in_channel == 1:\n",
        "    ax[7][i].imshow(vis_im_transform(y_test[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[7][i].imshow(vis_im_transform(y_test[i, ...]))\n",
        "\n",
        "for i in range(nCol):\n",
        "  ax[8][i].set_title('Test (Langevin)')\n",
        "  if in_channel == 1:\n",
        "    ax[8][i].imshow(vis_im_transform(y_update_test[i, ...]), cmap='gray')\n",
        "  else:\n",
        "    ax[8][i].imshow(vis_im_transform(y_update_test[i, ...]))\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.savefig(file_figure, bbox_inches='tight', dpi=600)\n",
        "plt.close(fig)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
